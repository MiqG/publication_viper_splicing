"""
Author: Miquel Anglada Girotto
Contact: miquelangladagirotto [at] gmail [dot] com
"""

import os
import pandas as pd

# variables
ROOT = os.path.dirname(os.path.dirname(os.getcwd()))
RAW_DIR = os.path.join(ROOT,"data","raw")
PREP_DIR = os.path.join(ROOT,"data","prep")
SUPPORT_DIR = os.path.join(ROOT,"support")
RESULTS_DIR = os.path.join(ROOT,"results","sf_targets_inference")

METHODS_INFER = ["correlation_spearman","aracne"]
CELL_LINES = ["K562","HepG2"]

CANCER_TYPES = [
#     'ACC',
#     'BLCA',
#     'BRCA',
#     'CESC',
#     'CHOL',
#     'COAD',
#     'DLBC',
#     #'ESCA',
#     'GBM',
#     'HNSC',
#     'KICH',
#     'KIRC',
#     'KIRP',
#     #'LAML',
#     'LGG',
    'LIHC',
#     'LUAD',
#     'LUSC',
#     'MESO',
#     #'OV',
#     'PAAD',
#     'PCPG',
#     'PRAD',
#     'READ',
#     'SARC',
#     'SKCM',
#     #'STAD',
#     'TGCT',
#     'THCA',
#     'THYM',
#     'UCEC',
#     'UCS',
#     'UVM'
]
DATASETS = CANCER_TYPES + ["CCLE"]

TARGETS_FILES = {
    "event_psi_imputed": os.path.join(PREP_DIR,"event_psi_imputed","{dataset}-EX.tsv.gz"),
    "event_psi": os.path.join(PREP_DIR,"event_psi","{dataset}-EX.tsv.gz"),
    "genexpr_tpm": os.path.join(PREP_DIR,"genexpr_tpm","{dataset}.tsv.gz")
}

SIGNATURE_FILES = {
    #"event_psi": os.path.join(PREP_DIR,'ground_truth_kd','ENCORE',"{cell_line}",'delta_psi-EX.tsv.gz'),
    "event_psi": os.path.join(PREP_DIR,'ground_truth_kd','ENCORE',"{cell_line}",'delta_psi_rel-EX-masked.tsv.gz'),
    "genexpr_tpm": os.path.join(PREP_DIR,'ground_truth_kd','ENCORE',"{cell_line}",'log2_fold_change_tpm.tsv.gz')
}


OMICS = ["event_psi"]#,"genexpr_tpm"]
N_BOOTSTRAPS = 100
BOOTSTRAPS = list(range(N_BOOTSTRAPS))
##### RULES #####
rule all:
    input:
        # run ARACNe
        ## prep inputs aracne
        expand(os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","upstream_regs.tsv"), omic=OMICS, dataset=DATASETS),
        expand(os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","upstream_regulators.txt"), omic=OMICS, dataset=DATASETS),
        expand(os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","targets.tsv"), omic=OMICS, dataset=DATASETS),
        ## infer threshold
        expand(os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}",".done_threshold"), omic=OMICS, dataset=DATASETS),
        ## bootstrap
        expand(os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}",".done_bootstrap_{boot_i}"), omic=OMICS, dataset=DATASETS, boot_i=BOOTSTRAPS),
        ## consolidate
        expand(os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","network.txt"), omic=OMICS, dataset=DATASETS),
        ## prep outputs for viper
        expand(os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","regulons.tsv.gz"), omic=OMICS, dataset=DATASETS),

        # infer activities with VIPER
        expand(os.path.join(RESULTS_DIR,'files','validations','{method}','{omic}','ENCORE','{cell_line}-{dataset}_regulons.tsv.gz'), method=["aracne"], omic=OMICS, cell_line=CELL_LINES, dataset=DATASETS),

        # make figures
        expand(os.path.join(RESULTS_DIR,'figures','validations',"{cell_line}","{omic}","{dataset}"), cell_line=CELL_LINES, omic=OMICS, dataset=DATASETS)

        # target inference
        ## correlations
        #expand(os.path.join(RESULTS_DIR,"files","target_inference","{method}","{omic}","{dataset}.tsv.gz"), method=["correlation_spearman"], dataset=DATASETS, omic=OMICS),
        ## aracne
        #expand(os.path.join(RESULTS_DIR,"files","target_inference","aracne_py","{omic}","{dataset}.tsv.gz"), dataset=DATASETS, omic=OMICS),

        # evaluation
        #expand(os.path.join(RESULTS_DIR,"files","inference_evaluation","{method}-{cell_line}.tsv.gz"), method=METHODS_INFER, cell_line=CELL_LINES),
        #os.path.join(RESULTS_DIR,"files","inference_evaluation","merged.tsv.gz"),
        
        

rule target_inference_aracne_java_prep_inputs:
    input:
        regulators = os.path.join(PREP_DIR,"genexpr_tpm","{dataset}.tsv.gz"),
        regulators_oi = os.path.join(SUPPORT_DIR,"GOBP_RNA_SPLICING-ensembl.txt"),
        targets = lambda wildcards: TARGETS_FILES[wildcards.omic] if wildcards.omic!="event_psi" else TARGETS_FILES[wildcards.omic+"_imputed"],
    output:
        regulators = os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","upstream_regs.tsv"),
        regulators_oi = os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","upstream_regulators.txt"),
        targets = os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","targets.tsv")
    params:
        omic = "{omic}"
    threads: 1
    resources:
        runtime = 3600*1, # h (event PSI needs more time)
        memory = 20, #GB
    run:
        import pandas as pd
        
        # load
        regulators = pd.read_table(input.regulators, index_col=0)
        regulators_oi = list(pd.read_table(input.regulators_oi, header=None)[0])
        targets = pd.read_table(input.targets, index_col=0)
        omic = params.omic
        
        # indices
        regulators.index.name = "regulator"
        targets.index.name = "target"
        
        # subset
        common_regulators = set(regulators_oi).intersection(regulators.index)
        regulators = regulators.loc[common_regulators].copy()
        
        # check order
        common_samples = set(targets.columns).intersection(regulators.columns)
        targets = targets[common_samples].copy()
        regulators = regulators[common_samples].copy()

        # drop events and genes with little variation (less than 1%)
        targets = targets.loc[(targets.std(1) / targets.mean(1)) > 0.01]
        regulators = regulators.loc[(regulators.std(1) / regulators.mean(1)) > 0.01]
        
        # add regulators to targets matrix for correct DPI, when different omics
        if omic != "genexpr_tpm":
            targets = pd.concat([targets,regulators])
        
        # DEV #########
        #regulators = regulators.iloc[:100]
        #targets = targets.iloc[:100]
        
        # save
        regulators.reset_index().to_csv(output.regulators, sep="\t", index=None)
        pd.DataFrame(regulators.index).to_csv(
            output.regulators_oi, sep="\t", index=None, header=False
        )
        targets.reset_index().to_csv(output.targets, sep="\t", index=None)
        
        print("Done!")
        

rule target_inference_aracne_java_threshold:
    input:
        regulators = os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","upstream_regs.tsv"),
        regulators_oi = os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","upstream_regulators.txt"),
        targets = os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","targets.tsv")
    output:
        touch(os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}",".done_threshold")),
    params:
        aracne_bin = "~/repositories/ARACNe-AP/dist/aracne.jar",
        random_seed = 1,
        output_dir = os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}"),
        mi_pvalue_thresh = "1E-8"
    threads: 12
    resources:
        runtime = 3600*12, # h (event PSI needs more time)
        memory = 15,
    shell:
        """
        java -Xmx{resources.memory}G -jar {params.aracne_bin} \
                --expfile_upstream {input.regulators} \
                --tfs {input.regulators_oi} \
                --expfile_downstream {input.targets} \
                --output {params.output_dir} \
                --pvalue {params.mi_pvalue_thresh} \
                --seed {params.random_seed} \
                --threads {threads} \
                --calculateThreshold
        """
        
        
rule target_inference_aracne_java_bootstrap:
    input:
        os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}",".done_threshold"),
        regulators = os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","upstream_regs.tsv"),
        regulators_oi = os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","upstream_regulators.txt"),
        targets = os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","targets.tsv")
    output:
        touch(os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}",".done_bootstrap_{boot_i}"))
    params:
        aracne_bin = "~/repositories/ARACNe-AP/dist/aracne.jar",
        output_dir = os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}"),
        random_seed = "{boot_i}"
    threads: 12
    resources:
        runtime = 3600*2, # h (event PSI needs more time)
        memory = 10,
    shell:
        """
        java -Xmx{resources.memory}G -jar {params.aracne_bin} \
                --expfile_upstream {input.regulators} \
                --tfs {input.regulators_oi} \
                --expfile_downstream {input.targets} \
                --output {params.output_dir} \
                --pvalue 1E-8 \
                --seed {params.random_seed} \
                --threads {threads}
        """
        
        
rule target_inference_aracne_java_consolidation:
    input:
        os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}",".done_threshold"),
        [os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}",".done_bootstrap_{boot_i}").format(boot_i=boot_i, omic="{omic}", dataset="{dataset}") for boot_i in BOOTSTRAPS]
    output:
        os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","network.txt")
    params:
        aracne_bin = "~/repositories/ARACNe-AP/dist/aracne.jar",
        output_dir = os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}"),
        consolidate_pvalue = 1.1
    threads: 12
    resources:
        runtime = 3600*12, # h (event PSI needs more time)
        memory = 30,
    shell:
        """
        java -Xmx{resources.memory}G -jar {params.aracne_bin} \
                --output {params.output_dir} \
                --threads {threads} \
                --consolidatepvalue {params.consolidate_pvalue} \
                --nobonferroni \
                --consolidate
        """
        
        
rule target_inference_aracne_java_prep_output:
    input:
        regulons = os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","network.txt"),
        regulators = os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","upstream_regs.tsv"),
        targets = os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","targets.tsv")
    output:
        regulons = os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","regulons.tsv.gz"),
        interactions_regulators = os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","interactions_regulators.tsv.gz")
    threads: 12
    resources:
        runtime = 3600*12, # h (event PSI needs more time)
        memory = 15, #GB
    params:
        padj_method = "fdr_bh",
        padj_threshold = 0.05
    run:
        import pandas as pd
        from statsmodels.stats.multitest import multipletests
        from joblib import Parallel, delayed
        from tqdm import tqdm
        
        # load
        regulons = pd.read_table(input.regulons)
        regulators = pd.read_table(input.regulators, index_col=0)
        targets = pd.read_table(input.targets, index_col=0)
        padj_method = params.padj_method
        padj_threshold = params.padj_threshold
        n_jobs = threads
        
        # split regulator-target interactions from regulator-regulator interactions
        is_reg_reg = regulons["Target"].isin(regulators.index)
        interactions_regulators = regulons.loc[is_reg_reg].copy()
        regulons = regulons.loc[~is_reg_reg].copy()
        
        # prepare regulon
        ## multiple test correction
        _, regulons["padj"], _, _ = multipletests(
            regulons["pvalue"], method=padj_method
        )
        ## filter out non-significant regulator-targets
        regulons = regulons.loc[regulons["padj"] < padj_threshold].copy()
        
        ## "upstream_regulator" and "target" columns
        regulons["regulator"] = regulons["Regulator"]
        regulons["target"] = regulons["Target"]
        
        ## likelihood
        regulons["likelihood"] = regulons["MI"]
        
        # compute spearman correlation for each pair
        def correlate(reg, tar, reg_name, tar_name, method="spearman"):
            corr = reg.corr(tar, method=method)
            corr = pd.Series({"regulator": reg_name, "target": tar_name, "tfmode": corr})
            return corr
        
        tfmodes = Parallel(n_jobs=n_jobs)(
            delayed(correlate)(
                regulators.loc[regulator],
                targets.loc[target],
                regulator,
                target
            ) for regulator, target in tqdm(regulons[["regulator","target"]].values)
        )
        tfmodes = pd.DataFrame(tfmodes)
        regulons = pd.merge(regulons, tfmodes, on=["regulator","target"], how="left")
        
        #         regulons["tfmode"] = regulons.apply(
        #             lambda row: regulators.loc[row["regulator"]].corr(targets.loc[row["target"]], method="spearman"), axis=1
        #         )

        # save
        regulons.to_csv(output.regulons, sep="\t", index=None, compression="gzip")
        interactions_regulators.to_csv(output.interactions_regulators, sep="\t", index=None, compression="gzip")
        
        print("Done!")



rule run_viper:
    input:
        signature = lambda wildcards: SIGNATURE_FILES[wildcards.omic],
        regulons = os.path.join(RESULTS_DIR,"files","target_inference","{method}","{omic}","{dataset}","regulons.tsv.gz")
    output:
        os.path.join(RESULTS_DIR,'files','validations','{method}','{omic}','ENCORE','{cell_line}-{dataset}_regulons.tsv.gz')
    shell:
        """
        Rscript scripts/run_viper.R \
                    --signature_file={input.signature} \
                    --regulons_file={input.regulons} \
                    --output_file={output}
        """
        

rule figures_target_inference:
    input:
        viper_result = os.path.join(RESULTS_DIR,'files','validations','aracne','{omic}','ENCORE','{cell_line}-{dataset}_regulons.tsv.gz'),
        regulons = os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}","regulons.tsv.gz"),
        encore_logfc = os.path.join(PREP_DIR,'ground_truth_kd','ENCORE',"{cell_line}",'log2_fold_change_tpm.tsv.gz'),
        event_info = os.path.join(RAW_DIR,"VastDB","EVENT_INFO-hg38_noseqs.tsv")
    output:
        directory(os.path.join(RESULTS_DIR,'figures','validations',"{cell_line}","{omic}","{dataset}"))
    shell:
        """
        nice Rscript scripts/figures_target_inference.R \
                    --viper_result_file={input.viper_result} \
                    --encore_logfc_file={input.encore_logfc} \
                    --regulons_file={input.regulons} \
                    --event_info_file={input.event_info} \
                    --figs_dir={output}
        """

        
# rule target_inference_aracne_py:
#     input:
#         targets = lambda wildcards: TARGETS_FILES[wildcards.omic] if wildcards.omic!="event_psi" else TARGETS_FILES[wildcards.omic+"_imputed"],
#         upstream_regs = os.path.join(PREP_DIR,"genexpr_tpm","{dataset}.tsv.gz"),
#         upstream_regs_oi = os.path.join(SUPPORT_DIR,"GOBP_RNA_SPLICING-ensembl.txt"),
#     output:
#         os.path.join(RESULTS_DIR,"files","target_inference","aracne_py","{omic}","{dataset}.tsv.gz")
#     params:
#         method="aracne_py"
#     threads: 24
#     resources:
#         runtime = 3600*12, # h (event PSI needs more time)
#         memory = 15
#     shell:
#         """
#         nice python scripts/infer_targets.py \
#                     --targets_file={input.targets} \
#                     --upstream_regs_file={input.upstream_regs} \
#                     --upstream_regs_oi_file={input.upstream_regs_oi} \
#                     --method={params.method} \
#                     --n_jobs={threads} \
#                     --output_file={output}
#         """

        
# rule inference_evaluation:
#     input:
#         inference = os.path.join(RESULTS_DIR,"files","target_inference","{method}.tsv.gz"),
#         ground_truth_kd_dpsi = os.path.join(PREP_DIR,'ground_truth_kd','ENCORE',"{cell_line}",'delta_psi-EX.tsv.gz'),
#         ground_truth_kd_rel = os.path.join(PREP_DIR,'ground_truth_kd','ENCORE',"{cell_line}",'delta_psi_rel-EX.tsv.gz')
#     output:
#         os.path.join(RESULTS_DIR,"files","inference_evaluation","{method}-{cell_line}.tsv.gz")
#     threads: 16
#     shell:
#         """
#         nice python scripts/evaluate_inference.py \
#                     --inference_file={input.inference} \
#                     --ground_truth_kd_dpsi_file={input.ground_truth_kd_dpsi} \
#                     --ground_truth_kd_rel_file={input.ground_truth_kd_rel} \
#                     --n_jobs={threads} \
#                     --output_file={output}
#         """


#ruleorder: target_inference_aracne_py > target_inference
        
# rule target_inference:
#     input:
#         targets = lambda wildcards: TARGETS_FILES[wildcards.omic],
#         upstream_regs = os.path.join(PREP_DIR,"genexpr_tpm","{dataset}.tsv.gz"),
#         upstream_regs_oi = os.path.join(SUPPORT_DIR,"GOBP_RNA_SPLICING-ensembl.txt")
#     output:
#         os.path.join(RESULTS_DIR,"files","target_inference","{method}","{omic}","{dataset}.tsv.gz")
#     params:
#         method="{method}"
#     threads: 12
#     shell:
#         """
#         nice python scripts/infer_targets.py \
#                     --targets_file={input.targets} \
#                     --upstream_regs_file={input.upstream_regs} \
#                     --upstream_regs_oi_file={input.upstream_regs_oi} \
#                     --method={params.method} \
#                     --n_jobs={threads} \
#                     --output_file={output}
#         """
        
        
# rule target_inference_aracne_java:
#     input:
#         targets = lambda wildcards: TARGETS_FILES[wildcards.omic] if wildcards.omic!="event_psi" else TARGETS_FILES[wildcards.omic+"_imputed"],
#         upstream_regs = os.path.join(PREP_DIR,"genexpr_tpm","{dataset}.tsv.gz"),
#         upstream_regs_oi = os.path.join(SUPPORT_DIR,"GOBP_RNA_SPLICING-ensembl.txt"),
#         spearman = os.path.join(RESULTS_DIR,"files","target_inference","correlation_spearman","{omic}","{dataset}.tsv.gz")
#     output:
#         os.path.join(RESULTS_DIR,"files","target_inference","aracne","{omic}","{dataset}.tsv.gz")
#     params:
#         method="aracne"
#     threads: 24
#     resources:
#         runtime = 3600*12, # h (event PSI needs more time)
#         memory = 15
#     shell:
#         """
#         nice python scripts/infer_targets.py \
#                     --targets_file={input.targets} \
#                     --upstream_regs_file={input.upstream_regs} \
#                     --upstream_regs_oi_file={input.upstream_regs_oi} \
#                     --correlation_spearman_file={input.spearman} \
#                     --method={params.method} \
#                     --n_jobs={threads} \
#                     --output_file={output}
#         """
