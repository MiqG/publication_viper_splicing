"""
Author: Miquel Anglada Girotto
Contact: miquelangladagirotto [at] gmail [dot] com
Last Update: 2021-01-12

Workflow purpose
--------------
Preprocess raw data.

Outline
-------

"""

import os
import pandas as pd

# variables
ROOT = os.path.dirname(os.path.dirname(os.getcwd()))
RAW_DIR = os.path.join(ROOT,"data","raw")
SRC_DIR = os.path.join(ROOT,"src")
PREP_DIR = os.path.join(ROOT,"data","prep")
SUPPORT_DIR = os.path.join(ROOT,"support")
RESULTS_DIR = os.path.join(ROOT,"results","preprocess_data")

SAVE_PARAMS = {"sep":"\t", "index":False, "compression":"gzip"}

EVENT_TYPES = ["EX"]
CELL_LINES = ["K562","HepG2"]
DPSI_TYPES = ["delta_psi","delta_psi_rel"]
CANCER_TYPES = [
    'ACC',
    'BLCA',
    'BRCA',
    'CESC',
    'CHOL',
    'COAD',
    'DLBC',
    'ESCA',
    'GBM',
    'HNSC',
    'KICH',
    'KIRC',
    'KIRP',
    'LAML',
    'LGG',
    'LIHC',
    'LUAD',
    'LUSC',
    'MESO',
    'OV',
    'PAAD',
    'PCPG',
    'PRAD',
    'READ',
    'SARC',
    'SKCM',
    'STAD',
    'TGCT',
    'THCA',
    'THYM',
    'UCEC',
    'UCS',
    'UVM'
]

CANCER_TYPES_OI = ["LAML","LIHC"]

tcga_metadata = pd.read_table(os.path.join(RAW_DIR,"TCGA","metadata","PANCAN.tsv.gz"))
TCGA_N_SAMPLES = tcga_metadata["cancer_type"].value_counts().to_dict()

DATASETS = ["CCLE"] + CANCER_TYPES_OI

ENCORE_DATASETS = ["ENCOREKD","ENCOREKO"]

N_SAMPLES_ENA = {
    "sf_drugs": 108,
    "sf_ptms": 88,
    "ipsc_differentiation": 217 
}

##### RULES #####
rule all:
    input:
        # get list of splicing factors
        os.path.join(PREP_DIR,"references","splicing_factors"),
        
        # preprocess CCLE
        os.path.join(PREP_DIR,"metadata","CCLE.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","CCLE-EX.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","CCLE-ALTA.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","CCLE-ALTD.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","CCLE-INT.tsv.gz"),
        os.path.join(PREP_DIR,"genexpr_tpm","CCLE.tsv.gz"),
        os.path.join(PREP_DIR,"mutations","CCLE.tsv.gz"),

        # preprocess ENCORE
        os.path.join(PREP_DIR,"metadata","ENCOREKD.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","ENCOREKD-EX.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","ENCOREKD-ALTA.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","ENCOREKD-ALTD.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","ENCOREKD-INT.tsv.gz"),
        os.path.join(PREP_DIR,"genexpr_tpm","ENCOREKD.tsv.gz"),    
        
        # preprocess ENCOREKO
        os.path.join(PREP_DIR,"metadata","ENCOREKO.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","ENCOREKO-EX.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","ENCOREKO-ALTA.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","ENCOREKO-ALTD.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","ENCOREKO-INT.tsv.gz"),
        os.path.join(PREP_DIR,"genexpr_tpm","ENCOREKO.tsv.gz"),    

        # preprocess TCGA
        expand(os.path.join(PREP_DIR,"metadata","{cancer}.tsv.gz"), cancer=CANCER_TYPES),
        expand(os.path.join(PREP_DIR,"event_psi","{cancer}-EX.tsv.gz"), cancer=CANCER_TYPES),
        expand(os.path.join(PREP_DIR,"event_psi","{cancer}-ALTA.tsv.gz"), cancer=CANCER_TYPES),
        expand(os.path.join(PREP_DIR,"event_psi","{cancer}-ALTD.tsv.gz"), cancer=CANCER_TYPES),
        expand(os.path.join(PREP_DIR,"event_psi","{cancer}-INT.tsv.gz"), cancer=CANCER_TYPES),
        expand(os.path.join(PREP_DIR,'genexpr_tpm','{cancer}.tsv.gz'), cancer=CANCER_TYPES),
        expand(os.path.join(PREP_DIR,"mutations","{cancer}.tsv.gz"), cancer=CANCER_TYPES),
        os.path.join(PREP_DIR,"metadata","PANCAN.tsv.gz"),
        
        # preprocess ENASFS
        os.path.join(PREP_DIR,"metadata","ENASFS.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","ENASFS-EX.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","ENASFS-ALTA.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","ENASFS-ALTD.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","ENASFS-INT.tsv.gz"),
        os.path.join(PREP_DIR,"genexpr_tpm","ENASFS.tsv.gz"),    
        
        # PERTURBATION SCREENS
        ### ENCORE
        ### compute log FC TPM
        expand(os.path.join(PREP_DIR,'pert_transcriptomes','{dataset}',"{cell_line}",'log2_fold_change_tpm.tsv.gz'), cell_line=CELL_LINES, dataset=ENCORE_DATASETS),
        ### compute delta PSI
        expand(os.path.join(PREP_DIR,'pert_transcriptomes','{dataset}',"{cell_line}",'delta_psi-{event_type}.tsv.gz'), event_type=EVENT_TYPES, cell_line=CELL_LINES, dataset=ENCORE_DATASETS),
        expand(os.path.join(PREP_DIR,'pert_transcriptomes','{dataset}',"{cell_line}",'delta_psi_rel-{event_type}.tsv.gz'), event_type=EVENT_TYPES, cell_line=CELL_LINES, dataset=ENCORE_DATASETS),
        ### mask delta PSI
        expand(os.path.join(PREP_DIR,'ground_truth_pert','{dataset}',"{cell_line}",'{dpsi_type}-{event_type}-masked.tsv.gz'), event_type=EVENT_TYPES, cell_line=CELL_LINES, dpsi_type=DPSI_TYPES, dataset=ENCORE_DATASETS),
        ### simplify delta PSI and log FC TPM
        expand(os.path.join(PREP_DIR,'ground_truth_pert','{dataset}',"{cell_line}",'{dpsi_type}-{event_type}.tsv.gz'), event_type=EVENT_TYPES, dpsi_type=DPSI_TYPES, cell_line=CELL_LINES, dataset=ENCORE_DATASETS),
        expand(os.path.join(PREP_DIR,'ground_truth_pert','{dataset}',"{cell_line}",'log2_fold_change_tpm.tsv.gz'), cell_line=CELL_LINES, dataset=ENCORE_DATASETS),
        
        ## ENASFS
        ### delta PSI
        expand(os.path.join(PREP_DIR,'pert_transcriptomes','ENASFS','delta_psi-{event_type}.tsv.gz'), event_type=EVENT_TYPES),
        ### simplify delta PSI
        expand(os.path.join(PREP_DIR,'ground_truth_pert','ENASFS','delta_psi-{event_type}.tsv.gz'), event_type=EVENT_TYPES),
        
        # impute event PSI
        #expand(os.path.join(PREP_DIR,'event_psi_imputed','{dataset}-{event_type}.tsv.gz'), dataset=DATASETS, event_type=EVENT_TYPES),
        expand(os.path.join(PREP_DIR,'event_psi_imputed','{dataset}-{event_type}.tsv.gz'), dataset="CardosoMoreira2020", event_type=EVENT_TYPES),
        
        # preprocess POSTAR3
        os.path.join(PREP_DIR,"clip_peaks_mapped","POSTAR3.tsv.gz"),
        
        # compute summary stats
        expand(os.path.join(PREP_DIR,"summary_stats","event_psi_imputed","{dataset}-EX.tsv.gz"), dataset=DATASETS),
        expand(os.path.join(PREP_DIR,"summary_stats","genexpr_tpm","{dataset}.tsv.gz"), dataset=DATASETS),
        
        # preprocess DepMap
        os.path.join(PREP_DIR,"demeter2","CCLE.tsv.gz"),
        
        # preprocess Nijhuis2020
        os.path.join(PREP_DIR,"metadata","Nijhuis2020.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","Nijhuis2020-EX.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","Nijhuis2020-ALTA.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","Nijhuis2020-ALTD.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","Nijhuis2020-INT.tsv.gz"),
        os.path.join(PREP_DIR,"genexpr_tpm","Nijhuis2020.tsv.gz"),

        # preprocess Lu2021
        os.path.join(PREP_DIR,"metadata","Lu2021.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","Lu2021-EX.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","Lu2021-ALTA.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","Lu2021-ALTD.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","Lu2021-INT.tsv.gz"),
        os.path.join(PREP_DIR,"genexpr_tpm","Lu2021.tsv.gz"),
        
        # preprocess ENA datasets
        expand(os.path.join(PREP_DIR,"metadata","{dataset}.tsv.gz"), dataset=N_SAMPLES_ENA.keys()),
        expand(os.path.join(PREP_DIR,"event_psi","{dataset}-EX.tsv.gz"), dataset=N_SAMPLES_ENA.keys()),
        expand(os.path.join(PREP_DIR,"event_psi","{dataset}-ALTA.tsv.gz"), dataset=N_SAMPLES_ENA.keys()),
        expand(os.path.join(PREP_DIR,"event_psi","{dataset}-ALTD.tsv.gz"), dataset=N_SAMPLES_ENA.keys()),
        expand(os.path.join(PREP_DIR,"event_psi","{dataset}-INT.tsv.gz"), dataset=N_SAMPLES_ENA.keys()),
        expand(os.path.join(PREP_DIR,"genexpr_tpm","{dataset}.tsv.gz"), dataset=N_SAMPLES_ENA.keys()),
        
        # preprocess CardosoMoreira2020
        os.path.join(PREP_DIR,"metadata","CardosoMoreira2020.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","CardosoMoreira2020-EX.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","CardosoMoreira2020-ALTA.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","CardosoMoreira2020-ALTD.tsv.gz"),
        os.path.join(PREP_DIR,"event_psi","CardosoMoreira2020-INT.tsv.gz"),
        os.path.join(PREP_DIR,"genexpr_tpm","CardosoMoreira2020.tsv.gz"),
        
        # preprocess MetMap
        os.path.join(PREP_DIR,"metmap","CCLE.tsv.gz"),    
        
        # discretize data
        #expand(os.path.join(PREP_DIR,"event_psi_imputed_discretized_{method}","{dataset}-EX.tsv.gz"), dataset=DATASETS, method=["qep"]), # "gaussian",
        #expand(os.path.join(PREP_DIR,"genexpr_tpm_discretized_qep","{dataset}.tsv.gz"), dataset=DATASETS, method=["qep"]),
        
        # EDA data figures
        os.path.join(RESULTS_DIR,'figures','eda')
        

        
rule make_list_splicing_factors:
    input:
        spliceosome_db = os.path.join(SUPPORT_DIR,"splicing_factors","literature_suptabs","SpliceosomeDB-human.csv"),
        handcurated = os.path.join(SUPPORT_DIR,"splicing_factors","splicing_factors_handcurated-ensembl.txt"),
        rogalska = os.path.join(SUPPORT_DIR,"splicing_factors","literature_suptabs","Rogalska2022NatRevGen-suptab1.xlsx"),
        hegele = os.path.join(SUPPORT_DIR,"splicing_factors","literature_suptabs","Hegele2012MolCell-suptab1.xls"),
        seiler = os.path.join(SUPPORT_DIR,"splicing_factors","literature_suptabs","Seiler2018CellReports-suptab1.xlsx"),
        papasaikas = os.path.join(SUPPORT_DIR,"splicing_factors","literature_suptabs","Papasaikas2015MolCell-suptab2.xlsx"),
        go_rna_splicing = os.path.join(SUPPORT_DIR,"splicing_factors","splicing_factors_handcurated-ensembl.txt"),
        go_rna_binding = os.path.join(SUPPORT_DIR,"splicing_factors","splicing_factors_handcurated-ensembl.txt"),
        annot_hgnc = os.path.join(RAW_DIR,"HGNC","gene_annotations.tsv.gz"),
        annot_ensembl = os.path.join(RAW_DIR,"references","annotation-entrez_ensembl_symbol.tsv")
    output:
        directory(os.path.join(PREP_DIR,"references","splicing_factors"))
    run:
        import pandas as pd
        import numpy as np
        
        # load data
        spliceosome_db = pd.read_csv(input.spliceosome_db)
        rogalska = pd.read_excel(input.rogalska)
        hegele = pd.read_excel(input.hegele)
        seiler = pd.read_excel(input.seiler, skiprows=3, nrows=404)
        papasaikas = pd.read_excel(input.papasaikas)
        handcurated = pd.read_table(input.handcurated, header=None)[0].tolist()
        go_rna_splicing = pd.read_table(input.go_rna_splicing, header=None)[0].tolist()
        go_rna_binding = pd.read_table(input.go_rna_binding, header=None)[0].tolist()
        annot_hgnc = pd.read_table(input.annot_hgnc)
        
        # prepare symbol cleanup
        cleanup = annot_hgnc[["Approved symbol","Ensembl gene ID","NCBI Gene ID","Alias symbols","Previous symbols"]].copy()
        cleanup["aliases"] = cleanup["Alias symbols"] + ", " + cleanup["Previous symbols"]
        cleanup["aliases"] = cleanup["aliases"].str.split(", ")
        cleanup = cleanup.explode("aliases")
        
        annot = annot_hgnc[["Approved symbol","Ensembl gene ID","NCBI Gene ID"]].drop_duplicates().copy()
        annot = annot.rename(columns={
            "Approved symbol":"GENE", "Ensembl gene ID":"ENSEMBL", "NCBI Gene ID":"ENTREZ"
        })
        
        # add ensembl in all lists
        ## Rogalska
        ### Fix with HGNC
        X = pd.merge(rogalska, annot[["GENE"]], left_on="SYMBOL", right_on="GENE", how="left")
        idx_notfound = X["GENE"].isnull()
        X.loc[idx_notfound,"GENE"] = pd.merge(X.loc[idx_notfound], cleanup, left_on="SYMBOL", right_on="aliases", how="left")["Approved symbol"].values
        ### Fix manually
        X.loc[X["SYMBOL"]=="HNRPLL", "GENE"] = "HNRNPLL"
        ### standardize
        X = pd.merge(X[["SYMBOL","CLASS","FULL_NAME","GENE"]], annot, on="GENE", how="left")
        ### save
        rogalska = X.copy()
        rogalska["dataset"] = "Rogalska2022"
        
        ## Hegele
        ### Fix with HGNC
        X = pd.merge(hegele, annot[["GENE"]], left_on="Symbol", right_on="GENE", how="left")
        idx_notfound = X["GENE"].isnull()
        X.loc[idx_notfound,"GENE"] = pd.merge(X.loc[idx_notfound], cleanup, left_on="Symbol", right_on="aliases", how="left")["Approved symbol"].values
        ### Fix manually
        X.loc[X["Symbol"]=="SF3B14", "GENE"] = "SF3B6"
        ### standardize
        cols_oi = ["Symbol","Category","Group_short"] + ["GENE"]
        X = pd.merge(X[cols_oi], annot, on="GENE", how="left")
        ### save
        hegele = X.copy()
        hegele["dataset"] = "Hegele2012"
        
        ## Seiler
        ### Fix with HGNC
        X = pd.merge(seiler, annot[["GENE"]], left_on="Gene Symbol", right_on="GENE", how="left")
        idx_notfound = X["GENE"].isnull()
        X.loc[idx_notfound,"GENE"] = pd.merge(X.loc[idx_notfound], cleanup, left_on="Gene Symbol", right_on="aliases", how="left")["Approved symbol"].values
        ### drop not found (LOC649330)
        idx_notfound = X["GENE"].isnull()
        X = X.loc[~idx_notfound]
        ### standardize
        cols_oi = ["GENE"]
        X = pd.merge(X[cols_oi], annot, on="GENE", how="left")
        ### save
        seiler = X.copy()
        seiler["dataset"] = "Seiler2018"
        
        ## Papasaikas
        ### drop experimental columns
        papasaikas = papasaikas.drop(columns=["SiRNA","Well","Pool Catalog Number","Duplex Catalog Number","Robin Reed classification"]).drop_duplicates().copy()
        papasaikas = papasaikas.loc[~(papasaikas["GENE ID"]=="-")].copy()
        ### Fix with HGNC
        X = pd.merge(papasaikas, annot[["GENE"]], left_on="Gene Symbol", right_on="GENE", how="left")
        X["GENE ID"] = X["GENE ID"].astype(float)
        idx_notfound = X["GENE"].isnull()
        X.loc[idx_notfound,"GENE"] = pd.merge(X.loc[idx_notfound], annot, left_on=["GENE ID"], right_on=["ENTREZ"], how="left")["GENE_y"].values
        ### standardize
        cols_oi = ['Gene Symbol', 'GENE ID', 'Luhrmann classification', 'Network Classification        (1st level )', 'Network Classification        (2nd level )'] + ["GENE"]
        X = pd.merge(X[cols_oi], annot, on="GENE", how="left")
        ### save
        papasaikas = X.copy()
        papasaikas["dataset"] = "Papasaikas2015"
        
        ## SpliceosomeDB
        X = spliceosome_db.copy()
        ### Fix manually
        X.loc[X["Gene Symbol"]=="C11orf2", "Gene Symbol"] = "VPS51"
        X = X.loc[~X["Ensemble Gene ID"].isnull()]
        ### Fix with HGNC
        X = pd.merge(X, annot[["GENE"]], left_on="Gene Symbol", right_on="GENE", how="left")
        idx_notfound = X["GENE"].isnull()
        X.loc[idx_notfound,"GENE"] = pd.merge(X.loc[idx_notfound], cleanup, left_on="Gene Symbol", right_on="aliases", how="left")["Approved symbol"].values
        ### Fix with HGNC - ENSEMBL
        idx_notfound = X["GENE"].isnull()
        X.loc[idx_notfound,"GENE"] = pd.merge(X.loc[idx_notfound], annot[["GENE","ENSEMBL"]], left_on="Ensemble Gene ID", right_on="ENSEMBL", how="left")["GENE_y"].values
        ### Fix manually
        idx_notfound = X["GENE"].isnull()
        X.loc[idx_notfound]
        X.loc[X["Gene Symbol"]=="HIST1H4A", "GENE"] = "H4C1"
        X.loc[X["Gene Symbol"]=="HIST2H4A", "GENE"] = "H4C14"
        ### standardize
        cols_oi = ['Gene Symbol', 'Complex', 'Ensemble Gene ID', 'Class / family'] + ["GENE"]
        X = pd.merge(X[cols_oi], annot, on="GENE", how="left")
        ### save
        spliceosome_db = X.copy()
        spliceosome_db["dataset"] = "SpliceosomeDB"
        
        ## Hand-curated
        handcurated = annot.loc[annot["ENSEMBL"].isin(handcurated)].copy()
        handcurated["dataset"] = "HandCurated"
        
        # combine datasets
        cols_oi = ["GENE","ENSEMBL","ENTREZ","dataset"]
        sfs_combined = pd.concat([
            rogalska[cols_oi],
            hegele[cols_oi],
            seiler[cols_oi],
            papasaikas[cols_oi],
            handcurated[cols_oi]
        ])
        
        # select splicing factors
        splicing_factors = sfs_combined[["GENE","ENSEMBL","ENTREZ"]].drop_duplicates()
        
        # fix missing values
        splicing_factors.loc[splicing_factors["GENE"]=="RNU2-1","ENSEMBL"] = "ENSG00000274585"
        splicing_factors.loc[splicing_factors["GENE"]=="EIF3A","ENSEMBL"] = "ENSG00000107581"
        splicing_factors.loc[splicing_factors["GENE"]=="EIF3A","ENTREZ"] = 8661.0
        
        # add info
        splicing_factors["in_rogalska"] = splicing_factors["GENE"].isin(rogalska["GENE"])
        splicing_factors["in_hegele"] = splicing_factors["GENE"].isin(hegele["GENE"])
        splicing_factors["in_seiler"] = splicing_factors["GENE"].isin(seiler["GENE"])
        splicing_factors["in_papasaikas"] = splicing_factors["GENE"].isin(papasaikas["GENE"])
        splicing_factors["in_handcurated"] = splicing_factors["GENE"].isin(handcurated["GENE"])
        splicing_factors["in_spliceosome_db"] = splicing_factors["GENE"].isin(spliceosome_db["GENE"])
        splicing_factors["in_go_sf"] = splicing_factors["ENSEMBL"].isin(go_rna_splicing)
        splicing_factors["in_go_rbp"] = splicing_factors["ENSEMBL"].isin(go_rna_binding)
        
        # add spliceosome DB complex info
        splicing_factors = pd.merge(
            splicing_factors, 
            spliceosome_db.rename(columns={
                "Complex":"spliceosome_db_complex","Class / family":"spliceosome_db_class"
            })[["ENSEMBL","spliceosome_db_complex","spliceosome_db_class"]].drop_duplicates().dropna(), 
            on="ENSEMBL",
            how="left"
        )
        
        # save
        os.makedirs(output[0], exist_ok=True)
        splicing_factors.to_csv(os.path.join(output[0],"splicing_factors.tsv"), index=False, sep="\t")
        splicing_factors[["ENSEMBL"]].to_csv(os.path.join(output[0],"splicing_factors-ensembl.txt"), index=False, sep="\t", header=None)
        splicing_factors[["GENE"]].to_csv(os.path.join(output[0],"splicing_factors-symbol.txt"), index=False, sep="\t", header=None)
        
        print("Done!")
    
    
rule preprocess_ccle:
    input:
        sample_info = os.path.join(RAW_DIR,"DepMap","achilles_ccle","sample_info.csv"),
        ccle_cancer_types = os.path.join(RAW_DIR,"articles","Yu2019","ccle_metadata.xls"),
        sample_annotation = os.path.join(RAW_DIR,"CCLE","ENA_filereport-PRJNA523380-CCLE.tsv"),
        psi = os.path.join(RAW_DIR,'CCLE','vast_out','PSI-minN_1-minSD_0-noVLOW-min_ALT_use25-Tidy.tab.gz'),
        genexpr = os.path.join(RAW_DIR,'CCLE','vast_out','TPM-hg38-1019.tab.gz')
    output:
        metadata = os.path.join(PREP_DIR,"metadata","CCLE.tsv.gz"),
        psi_EX = os.path.join(PREP_DIR,'event_psi','CCLE-EX.tsv.gz'),
        psi_ALTA = os.path.join(PREP_DIR,'event_psi','CCLE-ALTA.tsv.gz'),
        psi_ALTD = os.path.join(PREP_DIR,'event_psi','CCLE-ALTD.tsv.gz'),
        psi_INT = os.path.join(PREP_DIR,'event_psi','CCLE-INT.tsv.gz'),
        genexpr = os.path.join(PREP_DIR,'genexpr_tpm','CCLE.tsv.gz')      
    run:
        import gc
        import pandas as pd
        import numpy as np
        
        # load
        print("Loading data...")
        sample_info = pd.read_csv(input.sample_info)
        cancer_types = pd.read_excel(input.ccle_cancer_types)
        sample_annot = pd.read_table(input.sample_annotation)
        psi = pd.read_table(input.psi, index_col=0)
        genexpr = pd.read_table(input.genexpr, index_col=[0,1])
        
        gc.collect()
        
        # metadata
        ## preprocess
        sample_annot = sample_annot.rename(
            columns={"sample_alias": "CCLE_Name"}
        )
        sample_annot = sample_annot.loc[sample_annot["library_strategy"] == "RNA-Seq"]
        cancer_types = cancer_types.rename(
            columns={"CCLE_name": "CCLE_Name", "disease": "cancer_type"}
        )

        ## combine
        metadata = pd.merge(sample_info, cancer_types, on="CCLE_Name", how="left")
        metadata = pd.merge(
            metadata,
            sample_annot[["run_accession", "CCLE_Name"]],
            on="CCLE_Name",
            how="left",
        )   
        
        # PSI
        print("Processing PSI matrix...")
        ## drop empty rows
        is_na = psi.isnull()
        non_missing = is_na.shape[1] - is_na.sum(1)
        to_keep = non_missing >= 1
        psi = psi.loc[to_keep]
        
        ## remove vast-tools' suffix
        psi.columns = [c.replace('_1','') for c in psi.columns]
        
        ## split by event type
        event_types = ["EX","ALTA","ALTD","INT"]
        psis = {e: psi.loc[psi.index.str.contains(e)] for e in event_types}
        
        # TPM
        print("Processing TPM matrix...")
        ## remove vast-tools' suffix
        genexpr.columns = [c.replace('_1','') for c in genexpr.columns]
        
        ## log-transform
        genexpr = np.log2(genexpr + 1)
        
        # subset
        ## find common samples
        common_samples = set(metadata["run_accession"]).intersection(
            psis["EX"].columns
        ).intersection(
            genexpr.columns
        )
        psis = {e: psis[e][common_samples].copy() for e in event_types}
        genexpr = genexpr[common_samples].copy()
        metadata = metadata.loc[metadata["run_accession"].isin(common_samples)]
        
        ## rename columns
        psis = {
            e: psis[e].rename(
                columns=metadata.set_index("run_accession")["DepMap_ID"].to_dict()
                ).copy() 
            for e in event_types
        }
        genexpr = genexpr.rename(
            columns=metadata.set_index("run_accession")["DepMap_ID"].to_dict()
        ).copy()
        
        # save
        print("Saving...")
        ## metadata
        metadata.to_csv(output.metadata, **SAVE_PARAMS)

        ## PSIs
        psis["EX"].reset_index().to_csv(output.psi_EX, **SAVE_PARAMS)
        psis["ALTD"].reset_index().to_csv(output.psi_ALTD, **SAVE_PARAMS)
        psis["ALTA"].reset_index().to_csv(output.psi_ALTA, **SAVE_PARAMS)
        psis["INT"].reset_index().to_csv(output.psi_INT, **SAVE_PARAMS)
        
        ## TPMs
        genexpr.reset_index().drop(columns='NAME').to_csv(output.genexpr, **SAVE_PARAMS)
        
        print("Done!")        

        
rule preprocess_CCLE_mutations:
    input:
        mutations = os.path.join(RAW_DIR,"DepMap","achilles_ccle","CCLE_mutations.csv"),
        annot = os.path.join(RAW_DIR,"HGNC","gene_annotations.tsv.gz")
    output:
        mutations = os.path.join(PREP_DIR,"mutations","CCLE.tsv.gz")
    run:
        import pandas as pd
        
        mutations = pd.read_csv(input.mutations, low_memory=False)
        annot = pd.read_table(input.annot)
        
        annot = annot.rename(columns={"Approved symbol":"GENE","Ensembl gene ID":"ENSEMBL"})[["GENE","ENSEMBL"]]
        mutations = pd.merge(mutations, annot, left_on="Hugo_Symbol", right_on="GENE", how="left")
        
        mutations["sampleID"] = mutations["DepMap_ID"]
        mutations["mutation_effect"] = mutations["Variant_Classification"]
        
        # indicate aberrant mutations
        mutations_oi = [
            # CCLE
            "Frame_Shift_Del","Frame_Shift_Ins",
            "De_novo_Start_OutOfFrame", "Nonsense_Mutation"
        ]
        mutations["is_aberrant"] = mutations["mutation_effect"].isin(mutations_oi)
        
        mutations.to_csv(output.mutations, **SAVE_PARAMS)
        
        print("Done!")
        

rule preprocess_TCGA:
    input:
        metadata = os.path.join(RAW_DIR,"TCGA","metadata","{cancer}.tsv.gz"),
        psi = os.path.join(RAW_DIR,"TCGA","{cancer}","vast_out",'PSI-minN_1-minSD_0-noVLOW-min_ALT_use25-Tidy.tab.gz'),
        genexpr = lambda wildcards: os.path.join(RAW_DIR,"TCGA","{cancer}","vast_out",'TPM-hg38-{n_samples}.tab.gz').format(cancer='{cancer}', n_samples=TCGA_N_SAMPLES[wildcards.cancer])
    output:
        metadata = os.path.join(PREP_DIR,"metadata","{cancer}.tsv.gz"),
        psi_EX = os.path.join(PREP_DIR,"event_psi","{cancer}-EX.tsv.gz"),
        psi_ALTA = os.path.join(PREP_DIR,"event_psi","{cancer}-ALTA.tsv.gz"),
        psi_ALTD = os.path.join(PREP_DIR,"event_psi","{cancer}-ALTD.tsv.gz"),
        psi_INT = os.path.join(PREP_DIR,"event_psi","{cancer}-INT.tsv.gz"),
        genexpr = os.path.join(PREP_DIR,'genexpr_tpm','{cancer}.tsv.gz')      
    run:
        import gc
        import pandas as pd
        import numpy as np

        # load
        print("Loading data...")
        metadata = pd.read_table(input.metadata)
        psi = pd.read_table(input.psi, index_col=0)
        genexpr = pd.read_table(input.genexpr, index_col=[0,1])

        gc.collect()

        # preprocess metadata
        ## drop FFPE samples
        metadata = metadata.loc[~metadata["is_ffpe"],:].copy()

        # PSI
        print("Processing PSI matrix...")
        ## drop empty rows
        is_na = psi.isnull()
        non_missing = is_na.shape[1] - is_na.sum(1)
        to_keep = non_missing >= 1
        psi = psi.loc[to_keep]

        ## remove vast-tools' suffix
        psi.columns = [c.replace("_1","") for c in psi.columns]
        
        ## split by event type
        event_types = ["EX","ALTA","ALTD","INT"]
        psis = {e: psi.loc[psi.index.str.contains(e)] for e in event_types}        
        
        ## keep only the replicate with less missing values for each patient
        duplicated_sampleIDs = metadata.loc[metadata.duplicated('sampleID'),'sampleID'].unique()
        if len(duplicated_sampleIDs)>0:
            duplicated_file_ids = metadata.set_index('sampleID').loc[duplicated_sampleIDs,'file_id']

            # decide which sample to keep based on their missing values
            nan_count = psi[duplicated_file_ids].isnull().sum()
            file_ids_todrop = {sampleID: list(nan_count[duplicated_file_ids[sampleID]].sort_values().index[1:])
                               for sampleID in duplicated_file_ids.index.unique()}
            # drop samples
            file_ids_todrop = sum(list(file_ids_todrop.values()),[]) # unlist
            metadata = metadata.loc[~metadata['file_id'].isin(file_ids_todrop)]
            
        # TPM
        print("Processing TPM matrix...")
        ## remove vast-tools' suffix
        genexpr.columns = [c.replace('_1','') for c in genexpr.columns]
        
        ## log-transform
        genexpr = np.log2(genexpr + 1)
            
        # subset
        ## find common samples
        common_samples = set(metadata["file_id"]).intersection(
            psis["EX"].columns
        ).intersection(
            genexpr.columns
        )
        psis = {e: psis[e][common_samples].copy() for e in event_types}
        genexpr = genexpr[common_samples].copy()
        metadata = metadata.loc[metadata["file_id"].isin(common_samples)]
        
        ## rename columns
        psis = {
            e: psis[e].rename(
                columns=metadata.set_index("file_id")["sampleID"].to_dict()
                ).copy() 
            for e in event_types
        }
        genexpr = genexpr.rename(
            columns=metadata.set_index("file_id")["sampleID"].to_dict()
        ).copy()        
            
        # save
        print("Saving...")
        ## metadata
        metadata.to_csv(output.metadata, **SAVE_PARAMS)
        ## PSIs
        psis["EX"].reset_index().to_csv(output.psi_EX, **SAVE_PARAMS)
        psis["ALTD"].reset_index().to_csv(output.psi_ALTD, **SAVE_PARAMS)
        psis["ALTA"].reset_index().to_csv(output.psi_ALTA, **SAVE_PARAMS)
        psis["INT"].reset_index().to_csv(output.psi_INT, **SAVE_PARAMS)
        
        ## TPMs
        genexpr.reset_index().drop(columns='NAME').to_csv(output.genexpr, **SAVE_PARAMS)
        
        print("Done!")

        
rule preprocess_TCGA_mutations:
    input:
        mutations = os.path.join(RAW_DIR,"UCSCXena","GDC","snv","GDC-PANCAN.mutect2_snv.tsv.gz"),
        metadata = os.path.join(PREP_DIR,"metadata","{cancer}.tsv.gz"),
        annot = os.path.join(RAW_DIR,"HGNC","gene_annotations.tsv.gz")
    output:
        mutations = os.path.join(PREP_DIR,"mutations","{cancer}.tsv.gz")
    run:
        import pandas as pd
        
        mutations = pd.read_table(input.mutations, low_memory=False)
        metadata = pd.read_table(input.metadata)
        annot = pd.read_table(input.annot)
        
        # prep
        mutations["sampleID"] = mutations["Sample_ID"].str[:15]
        
        # subset
        mutations = mutations.loc[mutations["sampleID"].isin(metadata["sampleID"])].copy()
        
        # add ENSEMBL
        annot = annot.rename(columns={"Approved symbol":"GENE","Ensembl gene ID":"ENSEMBL"})[["GENE","ENSEMBL"]]
        mutations = pd.merge(mutations, annot, left_on="gene", right_on="GENE", how="left")
        
        mutations["mutation_effect"] = mutations["effect"]
        
        # indicate aberrant mutations
        mutations["is_aberrant"] = (
            mutations["mutation_effect"].str.contains("frameshift") |
            mutations["mutation_effect"].str.contains("stop_gained") |
            mutations["mutation_effect"].str.contains("start_lost")
        )        
        
        # save
        mutations.to_csv(output.mutations, **SAVE_PARAMS)
        
        print("Done!")


rule merge_tcga_metadata:
    input:
        metadatas = [os.path.join(PREP_DIR,"metadata","{cancer}.tsv.gz").format(cancer=c) for c in CANCER_TYPES]
    output:
        metadata = os.path.join(PREP_DIR,"metadata","PANCAN.tsv.gz")
    run:
        import pandas as pd
        
        metadata = pd.concat([pd.read_table(f) for f in input.metadatas])
        
        metadata.to_csv(output[0], **SAVE_PARAMS)
        
        print("Done!")
        
        
rule preprocess_encorekd:
    input:
        metadata = os.path.join(RAW_DIR,'ENCODE','ENCORE','metadata','ENCORE.tsv'),
        psi = os.path.join(RAW_DIR,'ENCODE','ENCORE','vast_out','PSI-minN_1-minSD_0-noVLOW-min_ALT_use25-Tidy.tab.gz'),
        genexpr = os.path.join(RAW_DIR,'ENCODE','ENCORE','vast_out','TPM-hg38-1097.tab.gz')
    output:
        metadata = os.path.join(PREP_DIR,'metadata','ENCOREKD.tsv.gz'),
        psi_EX = os.path.join(PREP_DIR,'event_psi','ENCOREKD-EX.tsv.gz'),
        psi_ALTA = os.path.join(PREP_DIR,'event_psi','ENCOREKD-ALTA.tsv.gz'),
        psi_ALTD = os.path.join(PREP_DIR,'event_psi','ENCOREKD-ALTD.tsv.gz'),
        psi_INT = os.path.join(PREP_DIR,'event_psi','ENCOREKD-INT.tsv.gz'),
        genexpr = os.path.join(PREP_DIR,'genexpr_tpm','ENCOREKD.tsv.gz')
    run:
        import gc
        import pandas as pd
        import numpy as np
        
        # load
        print("Loading data...")
        metadata = pd.read_table(input.metadata)
        psi = pd.read_table(input.psi, index_col=0)
        genexpr = pd.read_table(input.genexpr, index_col=[0,1])
        
        gc.collect()
        
        # metadata
        print("Processing metadata...")
        ## sample names
        metadata["sampleID"] = metadata["dbxrefs"].str.replace("SRA:","")
        ## cell lines info
        metadata["cell_line"] = metadata["Biosample term name"]
        depmapids = {"K562":"ACH-000551", "HepG2":"ACH-000739"}
        metadata["DepMap_ID"] = [depmapids[c] for c in metadata["cell_line"]]
        ## perturbation info
        metadata["PERT_GENE"] = metadata["Experiment target"].str.replace("-human","")
        gene_annot = genexpr.index.to_frame().rename(columns={"ID":"PERT_ENSEMBL", "NAME":"PERT_GENE"})
        metadata = pd.merge(metadata, gene_annot, how="left", on="PERT_GENE")
        metadata["PERT_TYPE"] = "SHRNAKD"
        ## experiment
        metadata["experiment"] = metadata["Experiment accession"]
        ## replicate
        metadata["replicate"] = metadata["Biological replicate(s)"]
        
        ## controls
        ctls_exps = []
        ctls_samps = []
        for idx, row in metadata.iterrows():
            if isinstance(row["Controlled by"], str):
                # get file accession controls
                accs = row["Controlled by"]\
                        .replace("files","")\
                        .replace("/","")\
                        .replace(" ","")\
                        .split(",")
                idx = metadata["File accession"].isin(accs)

                # get experiment accession
                exps = metadata.loc[idx, "experiment"].unique()
                
                # get sample accession
                samps = metadata.loc[idx, "sampleID"].unique()
                
                # save
                exps = ','.join(np.sort(exps))
                samps = ','.join(np.sort(samps))
                ctls_exps.append(exps)
                ctls_samps.append(samps)
            else:
                ctls_exps.append(np.nan)
                ctls_samps.append(np.nan)
        metadata["control_experiment"] = ctls_exps
        metadata["control_samples"] = ctls_samps
        
        cols_oi = ['sampleID','cell_line', 'DepMap_ID', 'PERT_GENE', 'PERT_ENSEMBL', 'experiment', 
                   'control_experiment', 'control_samples','replicate']
        metadata = metadata[cols_oi].drop_duplicates()
        
        # PSI
        print("Processing PSI matrix...")
        ## drop empty rows
        is_na = psi.isnull()
        non_missing = is_na.shape[1] - is_na.sum(1)
        to_keep = non_missing >= 1
        psi = psi.loc[to_keep]
        
        ## remove vast-tools' suffix
        psi.columns = [c.replace('_1','') for c in psi.columns]
        
        ## split by event type
        event_types = ["EX","ALTA","ALTD","INT"]
        psis = {e: psi.loc[psi.index.str.contains(e)] for e in event_types}
        
        # TPM
        print("Processing TPM matrix...")
        ## remove vast-tools' suffix
        genexpr.columns = [c.replace('_1','') for c in genexpr.columns]
        ## log-transform
        genexpr = np.log2(genexpr + 1)
        
        # save
        print("Saving...")
        ## metadata
        metadata.to_csv(output.metadata, **SAVE_PARAMS)
        
        ## PSIs
        psis["EX"].reset_index().to_csv(output.psi_EX, **SAVE_PARAMS)
        psis["ALTD"].reset_index().to_csv(output.psi_ALTD, **SAVE_PARAMS)
        psis["ALTA"].reset_index().to_csv(output.psi_ALTA, **SAVE_PARAMS)
        psis["INT"].reset_index().to_csv(output.psi_INT, **SAVE_PARAMS)
        
        ## TPMs
        genexpr.reset_index().drop(columns='NAME').to_csv(output.genexpr, **SAVE_PARAMS)
        
        print("Done!")
        
        
rule preprocess_encoreko:
    input:
        metadata = os.path.join(RAW_DIR,'ENCODE','ENCORE','CRISPRKO','metadata','CRISPRKO.tsv'),
        psi = os.path.join(RAW_DIR,'ENCODE','ENCORE','CRISPRKO','vast_out','PSI-minN_1-minSD_0-noVLOW-min_ALT_use25-Tidy.tab.gz'),
        genexpr = os.path.join(RAW_DIR,'ENCODE','ENCORE','CRISPRKO','vast_out','TPM-hg38-924.tab.gz')
    output:
        metadata = os.path.join(PREP_DIR,'metadata','ENCOREKO.tsv.gz'),
        psi_EX = os.path.join(PREP_DIR,'event_psi','ENCOREKO-EX.tsv.gz'),
        psi_ALTA = os.path.join(PREP_DIR,'event_psi','ENCOREKO-ALTA.tsv.gz'),
        psi_ALTD = os.path.join(PREP_DIR,'event_psi','ENCOREKO-ALTD.tsv.gz'),
        psi_INT = os.path.join(PREP_DIR,'event_psi','ENCOREKO-INT.tsv.gz'),
        genexpr = os.path.join(PREP_DIR,'genexpr_tpm','ENCOREKO.tsv.gz')
    run:
        import gc
        import pandas as pd
        import numpy as np
        
        # load
        print("Loading data...")
        metadata = pd.read_table(input.metadata)
        psi = pd.read_table(input.psi, index_col=0)
        genexpr = pd.read_table(input.genexpr, index_col=[0,1])
        
        gc.collect()
        
        # metadata
        print("Processing metadata...")
        ## sample names
        metadata["sampleID"] = metadata["dbxrefs"].str.replace("SRA:","")
        ## cell lines info
        metadata["cell_line"] = metadata["Biosample term name"]
        depmapids = {"K562":"ACH-000551", "HepG2":"ACH-000739"}
        metadata["DepMap_ID"] = [depmapids[c] for c in metadata["cell_line"]]
        ## perturbation info
        metadata["PERT_GENE"] = metadata["Experiment target"].str.replace("-human","")
        gene_annot = genexpr.index.to_frame().rename(columns={"ID":"PERT_ENSEMBL", "NAME":"PERT_GENE"})
        metadata = pd.merge(metadata, gene_annot, how="left", on="PERT_GENE")
        metadata["PERT_TYPE"] = "CRISPRKO"
        ## experiment
        metadata["experiment"] = metadata["Experiment accession"]
        ## replicate
        metadata["replicate"] = metadata["Biological replicate(s)"]
        
        ## controls
        ctls_exps = []
        ctls_samps = []
        for idx, row in metadata.iterrows():
            if isinstance(row["Controlled by"], str):
                # get file accession controls
                accs = row["Controlled by"]\
                        .replace("files","")\
                        .replace("/","")\
                        .replace(" ","")\
                        .split(",")
                idx = metadata["File accession"].isin(accs)

                # get experiment accession
                exps = metadata.loc[idx, "experiment"].unique()
                
                # get sample accession
                samps = metadata.loc[idx, "sampleID"].unique()
                
                # save
                exps = ','.join(np.sort(exps))
                samps = ','.join(np.sort(samps))
                ctls_exps.append(exps)
                ctls_samps.append(samps)
            else:
                ctls_exps.append(np.nan)
                ctls_samps.append(np.nan)
        metadata["control_experiment"] = ctls_exps
        metadata["control_samples"] = ctls_samps
        
        cols_oi = ['sampleID','cell_line', 'DepMap_ID', 'PERT_GENE', 'PERT_ENSEMBL', 'experiment', 
                   'control_experiment', 'control_samples','replicate']
        metadata = metadata[cols_oi].drop_duplicates()
        
        # PSI
        print("Processing PSI matrix...")
        ## drop empty rows
        is_na = psi.isnull()
        non_missing = is_na.shape[1] - is_na.sum(1)
        to_keep = non_missing >= 1
        psi = psi.loc[to_keep]
        
        ## remove vast-tools' suffix
        psi.columns = [c.replace('_1','') for c in psi.columns]
        
        ## split by event type
        event_types = ["EX","ALTA","ALTD","INT"]
        psis = {e: psi.loc[psi.index.str.contains(e)] for e in event_types}
        
        # TPM
        print("Processing TPM matrix...")
        ## remove vast-tools' suffix
        genexpr.columns = [c.replace('_1','') for c in genexpr.columns]
        ## log-transform
        genexpr = np.log2(genexpr + 1)
        
        # save
        print("Saving...")
        ## metadata
        metadata.to_csv(output.metadata, **SAVE_PARAMS)
        
        ## PSIs
        psis["EX"].reset_index().to_csv(output.psi_EX, **SAVE_PARAMS)
        psis["ALTD"].reset_index().to_csv(output.psi_ALTD, **SAVE_PARAMS)
        psis["ALTA"].reset_index().to_csv(output.psi_ALTA, **SAVE_PARAMS)
        psis["INT"].reset_index().to_csv(output.psi_INT, **SAVE_PARAMS)
        
        ## TPMs
        genexpr.reset_index().drop(columns='NAME').to_csv(output.genexpr, **SAVE_PARAMS)
        
        print("Done!")
        

rule diff_tpm_encore:
    input:
        metadata = os.path.join(PREP_DIR,'metadata','{dataset}.tsv.gz'),
        genexpr = os.path.join(PREP_DIR,'genexpr_tpm','{dataset}.tsv.gz')
    output:
        diff_tpm = os.path.join(PREP_DIR,'pert_transcriptomes','{dataset}',"{cell_line}",'log2_fold_change_tpm.tsv.gz')
    params:
        cell_line = "{cell_line}"
    run:
        import pandas as pd
        import numpy as np
        
        metadata = pd.read_table(input.metadata)
        genexpr = pd.read_table(input.genexpr, index_col=0)
        cell_line = params.cell_line
        
        # subset by cell line
        metadata = metadata.loc[metadata["cell_line"]==cell_line].copy()
        
        # log transform (already done)
        #genexpr = np.log2(genexpr + 1)
        #genexpr.columns = [c.replace("_1","") for c in genexpr.columns]
        
        # as the difference between conditions and the mean of the conditions
        diff_tpm = {}
        for sample_oi in metadata["sampleID"]:
            # get the controls of the sample
            ctls = metadata.loc[metadata["sampleID"]==sample_oi, "control_samples"].values[0]
            
            # controls will be np.nan
            if isinstance(ctls,str):
                ctls = ctls.split(",")
                tpm_ctls = genexpr[ctls].mean(axis=1)
                
                # compute log2 fold-change
                dtpm = genexpr[sample_oi] - tpm_ctls
                
                diff_tpm[sample_oi] = dtpm
                
                del dtpm, tpm_ctls, ctls
                
        diff_tpm = pd.DataFrame(diff_tpm)
        
        # save
        diff_tpm.reset_index().to_csv(output.diff_tpm, sep="\t", index=False, compression="gzip")
        
        print("Done!")
        
        
rule delta_psi_encore:
    input:
        metadata = os.path.join(PREP_DIR,'metadata','{dataset}.tsv.gz'),
        psi = os.path.join(PREP_DIR,'event_psi','{dataset}-{event_type}.tsv.gz')
    output:
        delta_psi = os.path.join(PREP_DIR,'pert_transcriptomes','{dataset}','{cell_line}','delta_psi-{event_type}.tsv.gz'),
        delta_psi_rel = os.path.join(PREP_DIR,'pert_transcriptomes','{dataset}','{cell_line}','delta_psi_rel-{event_type}.tsv.gz')
    params:
        cell_line = "{cell_line}"
    run:
        import pandas as pd
        import numpy as np
        
        metadata = pd.read_table(input.metadata)
        psi = pd.read_table(input.psi, index_col=0)
        cell_line = params.cell_line
        
        # subset by cell line
        metadata = metadata.loc[metadata["cell_line"]==cell_line].copy()
        
        # delta PSI as the difference between conditions and the mean of the conditions
        delta_psi = {}
        delta_psi_rel = {}
        for sample_oi in metadata["sampleID"]:
            # get the controls of the sample
            ctls = metadata.loc[metadata["sampleID"]==sample_oi, "control_samples"].values[0]
            
            # controls will be np.nan
            if isinstance(ctls,str):
                ctls = ctls.split(",")
                psi_ctls = psi[ctls].mean(axis=1)
                
                # compute delta PSI
                dpsi = psi[sample_oi] - psi_ctls
                
                # compute relative delta PSI (% changed of possible change w.r.t control)
                extreme_psi = dpsi.copy()
                extreme_psi[dpsi < 0] = 0 - psi_ctls # if it has decreased, the minimum inclusion
                extreme_psi[dpsi > 0] = 100 - psi_ctls # if it has increased, the maximum inclusion
                extreme_psi[dpsi == 0] = 1 # no change (for completeness)
                
                ## what percentage of the maximum possible change in inclusion has occured?
                rel_dpsi = np.sign(dpsi) * (dpsi / extreme_psi) * 100
                
                delta_psi[sample_oi] = dpsi
                delta_psi_rel[sample_oi] = rel_dpsi
                
                del dpsi, rel_dpsi, psi_ctls, ctls
                
        
        delta_psi = pd.DataFrame(delta_psi)
        delta_psi_rel = pd.DataFrame(delta_psi_rel)
        
        # save
        delta_psi.reset_index().to_csv(output.delta_psi, sep="\t", index=False, compression="gzip")
        delta_psi_rel.reset_index().to_csv(output.delta_psi_rel, sep="\t", index=False, compression="gzip")
        
        print("Done!")
        
        
rule prepare_ground_truth_pert_dpsi:
    input:
        metadata = os.path.join(PREP_DIR,'metadata','{dataset}.tsv.gz'),
        dpsi = os.path.join(PREP_DIR,'pert_transcriptomes','{dataset}',"{cell_line}",'{dpsi_type}-{event_type}.tsv.gz'),
    params:
        cell_line = "{cell_line}"
    output:
        dpsi = os.path.join(PREP_DIR,'ground_truth_pert','{dataset}',"{cell_line}",'{dpsi_type}-{event_type}.tsv.gz'),
    run:
        import pandas as pd
        
        metadata = pd.read_table(input.metadata)
        dpsi = pd.read_table(input.dpsi, index_col=0)
        cell_line = params.cell_line
        
        # drop control samples
        metadata = metadata.loc[~metadata["PERT_ENSEMBL"].isnull()].copy()
        
        # subset by cell line
        metadata = metadata.loc[metadata["cell_line"]==cell_line].copy()
        
        dpsis = []
        for ensembl in metadata["PERT_ENSEMBL"].unique():
            samples_oi = metadata.loc[metadata["PERT_ENSEMBL"]==ensembl, "sampleID"]
            
            dpsi_avg = dpsi[samples_oi].mean(axis=1)
            dpsi_avg.name = ensembl
            dpsis.append(dpsi_avg)
            
        dpsis = pd.concat(dpsis, axis=1)

        dpsis.reset_index().to_csv(output.dpsi, **SAVE_PARAMS)
        
        print("Done!")
        
        
rule mask_dpsi:
    input:
        delta_psi = os.path.join(PREP_DIR,'ground_truth_pert','{dataset}','{cell_line}','delta_psi-{event_type}.tsv.gz'),
        delta_psi_tomask = os.path.join(PREP_DIR,'ground_truth_pert','{dataset}','{cell_line}','{dpsi_type}-{event_type}.tsv.gz')
    output:
        os.path.join(PREP_DIR,'ground_truth_pert','{dataset}',"{cell_line}",'{dpsi_type}-{event_type}-masked.tsv.gz')
    params:
        thresh = -1
    run:
        import pandas as pd
        import numpy as np
        
        # load
        delta_psi = pd.read_table(input.delta_psi, index_col=0)
        delta_psi_tomask = pd.read_table(input.delta_psi_tomask, index_col=0)
        thresh = params.thresh
        
        # mask
        delta_psi_tomask[np.abs(delta_psi) < thresh] = np.nan
        
        # save
        delta_psi_tomask.reset_index().to_csv(output[0], **SAVE_PARAMS)
        
        print("Done!")
        
        
rule prepare_ground_truth_pert_logFCtpm:
    input:
        metadata = os.path.join(PREP_DIR,'metadata','{dataset}.tsv.gz'),
        diff_tpm = os.path.join(PREP_DIR,'pert_transcriptomes','{dataset}',"{cell_line}",'log2_fold_change_tpm.tsv.gz')
    params:
        cell_line = "{cell_line}"
    output:
        diff_tpm = os.path.join(PREP_DIR,'ground_truth_pert','{dataset}',"{cell_line}",'log2_fold_change_tpm.tsv.gz')
    run:
        import pandas as pd
        
        metadata = pd.read_table(input.metadata)
        diff_tpm = pd.read_table(input.diff_tpm, index_col=0)
        cell_line = params.cell_line
        
        # drop control samples
        metadata = metadata.loc[~metadata["PERT_ENSEMBL"].isnull()].copy()
        
        # subset by cell line
        metadata = metadata.loc[metadata["cell_line"]==cell_line].copy()
        
        diff_tpms = []
        for ensembl in metadata["PERT_ENSEMBL"].unique():
            samples_oi = metadata.loc[metadata["PERT_ENSEMBL"]==ensembl, "sampleID"]
            
            diff_tpm_avg = diff_tpm[samples_oi].mean(axis=1)
            diff_tpm_avg.name = ensembl
            diff_tpms.append(diff_tpm_avg)
            
        diff_tpms = pd.concat(diff_tpms, axis=1)

        diff_tpms.reset_index().to_csv(output.diff_tpm, **SAVE_PARAMS)
        
        print("Done!")
    
    
rule impute_psi_tcga:
    input:
        os.path.join(PREP_DIR,'event_psi','{dataset}-{event_type}.tsv.gz')
    output:
        os.path.join(PREP_DIR,'event_psi_imputed','{dataset}-{event_type}.tsv.gz')
    params:
        method = 'knn',
        method_kws = '\'{"n_neighbors":5}\'',
        features_as_rows = True
    shell:
        """
        python scripts/impute_nan.py \
                    --input_file={input} \
                    --output_file={output} \
                    --method={params.method} \
                    --method_kws={params.method_kws} \
                    --features_as_rows={params.features_as_rows}
        """
        
        
rule map_clip_peaks_to_exons:
    input:
        peaks = os.path.join(RAW_DIR,'POSTAR3','human.txt.gz'),
        event_info = os.path.join(RAW_DIR,"VastDB","EVENT_INFO-hg38_noseqs.tsv")
    output:
        os.path.join(PREP_DIR,"clip_peaks_mapped","POSTAR3.tsv.gz")
    params:
        margin = 500
    run:
        import pandas as pd
        import pyranges as pr
        
        # load
        ## read peaks file
        col_names = [
            "Chromosome",
            "Start",
            "End",
            "peak_id",
            "Strand",
            "RBP",
            "experiment_method",
            "experiment_model",
            "experiment_id"
        ]
        peaks = pd.read_table(
            input.peaks,
            header=None,
            names=col_names
        )
        ## read vastdb events
        events = pd.read_table(input.event_info)
        ## params
        margin = params.margin
        
        # assign exons to peaks if a peak falls on the exon or one of its neighboring introns
        ## only event type of interest
        events = events.loc[events["EVENT"].str.contains("EX")].copy()
        ## process event coordinates
        events["Chromosome"] = (
            events["COORD_o"].str.split(":").str[0]
        )
        events["EVENT_start"] = (
            events["COORD_o"].str.split(":").str[1].str.split("-").str[0]
        ).astype("int")
        events["EVENT_end"] = (
            events["COORD_o"].str.split(":").str[1].str.split("-").str[1].astype("int")
        )
        events["Strand"] = (
            events["REF_CO"].str.split(":").str[2]
        )
        #         ## start and end will be the next splice site junctions
        #         events["Start"] = events["CO_C1"].str.split(":").str[1].str.split("-").str[1]
        #         events["End"] = events["CO_C2"].str.split(":").str[1].str.split("-").str[0]
        events["Start"] = events["EVENT_start"]
        events["End"] = events["EVENT_end"]
        
        # intersect
        ## prepare
        X = pr.PyRanges(
            events[["EVENT", "Chromosome", "Start", "End", "Strand"]],
            int64=True,
        )
        Y = pr.PyRanges(peaks, int64=True)
        ## join
        mapping = X.join(Y, slack=margin, how="left", report_overlap=True)
               
        # prepare outputs
        ## drop unmapped
        mapping = mapping.df.loc[~mapping.df["peak_id"].isin(["-1"])]
        ## rename
        mapping = mapping.rename(columns={
            "Start_b":"peak_start",
            "End_b":"peak_end"
        })
        
        # save
        mapping.to_csv(output[0], sep="\t", compression="gzip", index=False)
        
        print("Done!")
        
        
rule make_summary_stats_splicing:
    input:
        omic = os.path.join(PREP_DIR,"event_psi_imputed","{dataset}-EX.tsv.gz")
    output:
        os.path.join(PREP_DIR,"summary_stats","event_psi_imputed","{dataset}-EX.tsv.gz")
    run:
        import pandas as pd
        from scipy import stats
        
        def get_summary_stats(df, label):
            summary_stats = {
                label + "_mean": df.mean(axis=1),
                label + "_median": df.median(axis=1),
                label + "_std": df.std(axis=1),
                label + "_std_ddof0": df.std(axis=1, ddof=0),
                label + "_mad": df.apply(stats.median_abs_deviation, axis=1),
                label + "_q25": df.quantile(0.25, axis=1),
                label + "_q75": df.quantile(0.75, axis=1),
            }
            return summary_stats
        
        # load
        omic = pd.read_table(input.omic, index_col=0)
        
        # get summary stats
        summary_stats = pd.DataFrame(get_summary_stats(omic, "EVENT"))
        
        # save
        summary_stats.reset_index().to_csv(output[0], **SAVE_PARAMS)
        
        print("Done!")
        

rule make_summary_stats_genexpr:
    input:
        omic = os.path.join(PREP_DIR,"genexpr_tpm","{dataset}.tsv.gz")
    output:
        os.path.join(PREP_DIR,"summary_stats","genexpr_tpm","{dataset}.tsv.gz")
    run:
        import pandas as pd
        from scipy import stats
        
        def get_summary_stats(df, label):
            summary_stats = {
                label + "_mean": df.mean(axis=1),
                label + "_median": df.median(axis=1),
                label + "_std": df.std(axis=1),
                label + "_std_ddof0": df.std(axis=1, ddof=0),
                label + "_mad": df.apply(stats.median_abs_deviation, axis=1),
                label + "_q25": df.quantile(0.25, axis=1),
                label + "_q75": df.quantile(0.75, axis=1),
            }
            return summary_stats
        
        # load
        omic = pd.read_table(input.omic, index_col=0)
        
        # get summary stats
        summary_stats = pd.DataFrame(get_summary_stats(omic, "ENSEMBL"))
        
        # save
        summary_stats.reset_index().to_csv(output[0], **SAVE_PARAMS)
        
        print("Done!")
        
        
rule preprocess_demeter2:
    input:
        demeter2 = os.path.join(RAW_DIR,"DepMap","demeter2","D2_combined_gene_dep_scores.csv"),
        metadata = os.path.join(RAW_DIR,'DepMap','achilles_ccle','sample_info.csv')
    output:
        os.path.join(PREP_DIR,"demeter2","CCLE.tsv.gz")
    run:
        import pandas as pd
        
        # load
        demeter2 = pd.read_csv(input.demeter2, index_col=0)
        metadata = pd.read_csv(input.metadata)
        
        # PREPROCESS
        ## strip gene names
        demeter2.index = [symbol for symbol, entrez in demeter2.index.str.split(" ")]

        ## rename samples
        demeter2 = demeter2.rename(
            columns=metadata.set_index("CCLE_Name")["DepMap_ID"].to_dict()
        )

        ## drop rows missing many values
        is_na = demeter2.isnull()
        non_missing = is_na.shape[1] - is_na.sum(1)
        to_keep = non_missing >= 50
        demeter2 = demeter2.loc[to_keep].copy()
        
        # save
        demeter2.reset_index().to_csv(output[0], **SAVE_PARAMS)
        
        print("Done!")
        
        
rule preprocess_Nijhuis2020:
    input:
        metadata = os.path.join(SUPPORT_DIR,"ENA_filereport-PRJNA673205-Nijhuis2020.tsv"),
        metadata_proteomics = os.path.join(SUPPORT_DIR,"Nijhuis2020-metadata-proteomics.tsv"),
        psi = os.path.join(RAW_DIR,"articles","Nijhuis2020",'vast_out','PSI-minN_1-minSD_0-noVLOW-min_ALT_use25-Tidy.tab.gz'),
        genexpr = os.path.join(RAW_DIR,"articles","Nijhuis2020",'vast_out','TPM-hg38-6.tab.gz')
    output:
        metadata = os.path.join(PREP_DIR,"metadata","Nijhuis2020.tsv.gz"),
        psi_EX = os.path.join(PREP_DIR,'event_psi','Nijhuis2020-EX.tsv.gz'),
        psi_ALTA = os.path.join(PREP_DIR,'event_psi','Nijhuis2020-ALTA.tsv.gz'),
        psi_ALTD = os.path.join(PREP_DIR,'event_psi','Nijhuis2020-ALTD.tsv.gz'),
        psi_INT = os.path.join(PREP_DIR,'event_psi','Nijhuis2020-INT.tsv.gz'),
        genexpr = os.path.join(PREP_DIR,'genexpr_tpm','Nijhuis2020.tsv.gz')      
    run:
        import gc
        import pandas as pd
        import numpy as np
        
        # load
        print("Loading data...")
        metadata = pd.read_table(input.metadata)
        metadata_proteomics = pd.read_table(input.metadata_proteomics)
        psi = pd.read_table(input.psi, index_col=0)
        genexpr = pd.read_table(input.genexpr, index_col=[0,1])
        
        gc.collect()
        
        # metadata
        metadata["sampleID"] = metadata["run_accession"]
        
        # PSI
        print("Processing PSI matrix...")
        ## drop empty rows
        is_na = psi.isnull()
        non_missing = is_na.shape[1] - is_na.sum(1)
        to_keep = non_missing >= 1
        psi = psi.loc[to_keep]
        
        ## remove vast-tools' suffix
        psi.columns = [c.replace('_1','') for c in psi.columns]
        
        ## split by event type
        event_types = ["EX","ALTA","ALTD","INT"]
        psis = {e: psi.loc[psi.index.str.contains(e)] for e in event_types}
        
        # TPM
        print("Processing TPM matrix...")
        ## remove vast-tools' suffix
        genexpr.columns = [c.replace('_1','') for c in genexpr.columns]
        
        ## log-transform
        genexpr = np.log2(genexpr + 1)
        
        # subset
        ## find common samples
        common_samples = set(metadata["run_accession"]).intersection(
            psis["EX"].columns
        ).intersection(
            genexpr.columns
        )
        psis = {e: psis[e][common_samples].copy() for e in event_types}
        genexpr = genexpr[common_samples].copy()
        metadata = metadata.loc[metadata["run_accession"].isin(common_samples)]
        
        ## append metadata proteomics
        metadata_proteomics["sampleID"] = "sample"+metadata_proteomics["SampleNumber"].astype(str)
        
        # save
        print("Saving...")
        ## metadata
        metadata.to_csv(output.metadata, **SAVE_PARAMS)

        ## PSIs
        psis["EX"].reset_index().to_csv(output.psi_EX, **SAVE_PARAMS)
        psis["ALTD"].reset_index().to_csv(output.psi_ALTD, **SAVE_PARAMS)
        psis["ALTA"].reset_index().to_csv(output.psi_ALTA, **SAVE_PARAMS)
        psis["INT"].reset_index().to_csv(output.psi_INT, **SAVE_PARAMS)
        
        ## TPMs
        genexpr.reset_index().drop(columns='NAME').to_csv(output.genexpr, **SAVE_PARAMS)
        
        print("Done!")
        
        
rule preprocess_Lu2021:
    input:
        metadata = os.path.join(SUPPORT_DIR,"ENA_filereport-PRJNA683080-Lu2021.tsv"),
        psi = os.path.join(RAW_DIR,"articles","Lu2021",'vast_out','PSI-minN_1-minSD_0-noVLOW-min_ALT_use25-Tidy.tab.gz'),
        genexpr = os.path.join(RAW_DIR,"articles","Lu2021",'vast_out','TPM-hg38-27.tab.gz')
    output:
        metadata = os.path.join(PREP_DIR,"metadata","Lu2021.tsv.gz"),
        psi_EX = os.path.join(PREP_DIR,'event_psi','Lu2021-EX.tsv.gz'),
        psi_ALTA = os.path.join(PREP_DIR,'event_psi','Lu2021-ALTA.tsv.gz'),
        psi_ALTD = os.path.join(PREP_DIR,'event_psi','Lu2021-ALTD.tsv.gz'),
        psi_INT = os.path.join(PREP_DIR,'event_psi','Lu2021-INT.tsv.gz'),
        genexpr = os.path.join(PREP_DIR,'genexpr_tpm','Lu2021.tsv.gz')      
    run:
        import gc
        import pandas as pd
        import numpy as np
        
        # load
        print("Loading data...")
        metadata = pd.read_table(input.metadata)
        psi = pd.read_table(input.psi, index_col=0)
        genexpr = pd.read_table(input.genexpr, index_col=[0,1])
        
        gc.collect()
        
        # metadata
        metadata["sampleID"] = metadata["run_accession"]
        
        # PSI
        print("Processing PSI matrix...")
        ## drop empty rows
        is_na = psi.isnull()
        non_missing = is_na.shape[1] - is_na.sum(1)
        to_keep = non_missing >= 1
        psi = psi.loc[to_keep]
        
        ## remove vast-tools' suffix
        psi.columns = [c.replace('_1','') for c in psi.columns]
        
        ## split by event type
        event_types = ["EX","ALTA","ALTD","INT"]
        psis = {e: psi.loc[psi.index.str.contains(e)] for e in event_types}
        
        # TPM
        print("Processing TPM matrix...")
        ## remove vast-tools' suffix
        genexpr.columns = [c.replace('_1','') for c in genexpr.columns]
        
        ## log-transform
        genexpr = np.log2(genexpr + 1)
        
        # subset
        ## find common samples
        common_samples = set(metadata["run_accession"]).intersection(
            psis["EX"].columns
        ).intersection(
            genexpr.columns
        )
        psis = {e: psis[e][common_samples].copy() for e in event_types}
        genexpr = genexpr[common_samples].copy()
        metadata = metadata.loc[metadata["run_accession"].isin(common_samples)]
        
        # save
        print("Saving...")
        ## metadata
        metadata.to_csv(output.metadata, **SAVE_PARAMS)

        ## PSIs
        psis["EX"].reset_index().to_csv(output.psi_EX, **SAVE_PARAMS)
        psis["ALTD"].reset_index().to_csv(output.psi_ALTD, **SAVE_PARAMS)
        psis["ALTA"].reset_index().to_csv(output.psi_ALTA, **SAVE_PARAMS)
        psis["INT"].reset_index().to_csv(output.psi_INT, **SAVE_PARAMS)
        
        ## TPMs
        genexpr.reset_index().drop(columns='NAME').to_csv(output.genexpr, **SAVE_PARAMS)
        
        print("Done!")
        
        
rule preprocess_metmap:
    input:
        metmap = os.path.join(RAW_DIR,"DepMap","metmap","metmap500.xlsx"),
        metadata = os.path.join(RAW_DIR,'DepMap','achilles_ccle','sample_info.csv')
    output:
        os.path.join(PREP_DIR,"metmap","CCLE.tsv.gz")
    run:
        import pandas as pd
        
        tissues = ["brain","lung","liver","bone","kidney","all5"]        
        
        # load
        metadata = pd.read_csv(input.metadata)
        metmap = pd.concat([
            pd.read_excel(input.metmap, sheet_name=idx).rename(columns={
                "Unnamed: 0":"CCLE_Name",
                "CI.05": "CI.05_%s" % tissue,
                "CI.95": "CI.95_%s" % tissue,
                "mean": "mean_%s" % tissue,
                "penetrance": "penetrance_%s" % tissue
            }).set_index("CCLE_Name")
            
            for idx, tissue in enumerate(tissues)
        ], axis=1).reset_index()
        
        # add depmap id
        metmap = pd.merge(metmap, metadata[["CCLE_Name","DepMap_ID"]], how="left", on="CCLE_Name")
        
        # save
        metmap.to_csv(output[0], **SAVE_PARAMS)
        
        print("Done!")
        
        
rule preprocess_ena_datasets:
    input:
        metadata = os.path.join(SUPPORT_DIR,"ENA_filereport-{dataset}.tsv"),
        psi = os.path.join(RAW_DIR,"ENA","{dataset}",'vast_out','PSI-minN_1-minSD_0-noVLOW-min_ALT_use25-Tidy.tab.gz'),
        genexpr = lambda wildcards: os.path.join(RAW_DIR,"ENA","{dataset}",'vast_out','TPM-hg38-{n_samples}.tab.gz').format(n_samples=N_SAMPLES_ENA[wildcards.dataset], dataset=wildcards.dataset)
    output:
        metadata = os.path.join(PREP_DIR,"metadata","{dataset}.tsv.gz"),
        psi_EX = os.path.join(PREP_DIR,'event_psi','{dataset}-EX.tsv.gz'),
        psi_ALTA = os.path.join(PREP_DIR,'event_psi','{dataset}-ALTA.tsv.gz'),
        psi_ALTD = os.path.join(PREP_DIR,'event_psi','{dataset}-ALTD.tsv.gz'),
        psi_INT = os.path.join(PREP_DIR,'event_psi','{dataset}-INT.tsv.gz'),
        genexpr = os.path.join(PREP_DIR,'genexpr_tpm','{dataset}.tsv.gz')      
    run:
        import gc
        import pandas as pd
        import numpy as np
        
        # load
        print("Loading data...")
        metadata = pd.read_table(input.metadata)
        psi = pd.read_table(input.psi, index_col=0)
        genexpr = pd.read_table(input.genexpr, index_col=[0,1])
        
        gc.collect()
        
        # metadata
        metadata["sampleID"] = metadata["run_accession"]
        
        # PSI
        print("Processing PSI matrix...")
        ## drop empty rows
        is_na = psi.isnull()
        non_missing = is_na.shape[1] - is_na.sum(1)
        to_keep = non_missing >= 1
        psi = psi.loc[to_keep]
        
        ## remove vast-tools' suffix
        psi.columns = [c.replace('_1','') for c in psi.columns]
        
        ## split by event type
        event_types = ["EX","ALTA","ALTD","INT"]
        psis = {e: psi.loc[psi.index.str.contains(e)] for e in event_types}
        
        # TPM
        print("Processing TPM matrix...")
        ## remove vast-tools' suffix
        genexpr.columns = [c.replace('_1','') for c in genexpr.columns]
        
        ## log-transform
        genexpr = np.log2(genexpr + 1)
        
        # subset
        ## find common samples
        common_samples = set(metadata["run_accession"]).intersection(
            psis["EX"].columns
        ).intersection(
            genexpr.columns
        )
        psis = {e: psis[e][common_samples].copy() for e in event_types}
        genexpr = genexpr[common_samples].copy()
        metadata = metadata.loc[metadata["run_accession"].isin(common_samples)]
        
        # save
        print("Saving...")
        ## metadata
        metadata.to_csv(output.metadata, **SAVE_PARAMS)

        ## PSIs
        psis["EX"].reset_index().to_csv(output.psi_EX, **SAVE_PARAMS)
        psis["ALTD"].reset_index().to_csv(output.psi_ALTD, **SAVE_PARAMS)
        psis["ALTA"].reset_index().to_csv(output.psi_ALTA, **SAVE_PARAMS)
        psis["INT"].reset_index().to_csv(output.psi_INT, **SAVE_PARAMS)
        
        ## TPMs
        genexpr.reset_index().drop(columns='NAME').to_csv(output.genexpr, **SAVE_PARAMS)
        
        print("Done!")


rule preprocess_ena_splicing_factors:
    input:
        metadata = os.path.join(SUPPORT_DIR,'ENA_filereport-selected_sf_experiments_handcurated_w_control_samples.tsv'),
        metadata_groups = os.path.join(SUPPORT_DIR,"ENA_filereport-selected_sf_experiments_handcurated-low_read_count_groups.tsv"),
        psi = os.path.join(RAW_DIR,"ENA","splicing_factors",'vast_out','PSI-minN_1-minSD_0-noVLOW-min_ALT_use25-Tidy.tab.gz'),
        genexpr = os.path.join(RAW_DIR,"ENA","splicing_factors",'vast_out','TPM-hg38-1597.tab.gz')
    output:
        metadata = os.path.join(PREP_DIR,"metadata","ENASFS.tsv.gz"),
        psi_EX = os.path.join(PREP_DIR,'event_psi','ENASFS-EX.tsv.gz'),
        psi_ALTA = os.path.join(PREP_DIR,'event_psi','ENASFS-ALTA.tsv.gz'),
        psi_ALTD = os.path.join(PREP_DIR,'event_psi','ENASFS-ALTD.tsv.gz'),
        psi_INT = os.path.join(PREP_DIR,'event_psi','ENASFS-INT.tsv.gz'),
        genexpr = os.path.join(PREP_DIR,'genexpr_tpm','ENASFS.tsv.gz')      
    run:
        import gc
        import pandas as pd
        import numpy as np
        
        # load
        print("Loading data...")
        metadata = pd.read_table(input.metadata)
        metadata_groups = pd.read_table(input.metadata_groups)
        psi = pd.read_table(input.psi, index_col=0)
        genexpr = pd.read_table(input.genexpr, index_col=[0,1])
        
        gc.collect()
        
        # metadata
        ## not grouped metadata
        metadata_not_merged = metadata.loc[~metadata["run_accession"].isin(metadata_groups["run_accession"])].copy()
        metadata_not_merged["sampleID"] = metadata_not_merged["run_accession"]
        metadata_not_merged["control_samples"] = metadata_not_merged["control_samples"].str.replace(",","||")
        
        ## grouped metadata
        ### subset
        metadata_merged = metadata.loc[metadata["run_accession"].isin(metadata_groups["run_accession"])].copy()
        metadata_merged = pd.merge(metadata_merged, metadata_groups[["group_label","run_accession"]], how="left", on="run_accession")
        ### control_samples at the group level
        control_samples_group = []
        for ctls in metadata_merged["control_samples"].dropna().unique():
            # get run accessions
            run_accessions = ctls.split(",")
            
            # get corresponding group labels
            group_labs = metadata_merged.loc[metadata_merged["run_accession"].isin(run_accessions),"group_label"].unique()
            
            # join group labels
            ctls_group = "||".join(group_labs)
            
            # save
            control_samples_group.append({
                "control_samples": ctls,
                "control_samples_group": ctls_group
            })
        control_samples_group = pd.DataFrame(control_samples_group)
        metadata_merged = pd.merge(metadata_merged, control_samples_group, on="control_samples", how="left")
        metadata_merged["control_samples"] = metadata_merged["control_samples_group"]
        
        ### columns to keep
        cols_oi = [
            "study_accession","cell_line_name","condition","pert_time",
            "pert_time_units","pert_concentration","pert_concentration_units",
            'found_sfs_in_run_alias', 'found_sfs_in_sample_alias', 'found_sfs_in_sample_title', 
            'found_sfs_in_experiment_title', 'found_sfs_in_study_title', 'is_match', 'group_label',
            "DepMap_ID","CCLE_Name","PERT_GENE","PERT_ENSEMBL","IS_USEFUL","comments","PERT_TYPE",
            "control_samples"
        ]
        metadata_merged = metadata_merged[cols_oi].drop_duplicates().copy()
        metadata_merged["sampleID"] = metadata_merged["group_label"]
        
        ## combine metadatas
        metadata = pd.concat([metadata_not_merged, metadata_merged])
        
        # PSI
        print("Processing PSI matrix...")
        ## drop empty rows
        is_na = psi.isnull()
        non_missing = is_na.shape[1] - is_na.sum(1)
        to_keep = non_missing >= 1
        psi = psi.loc[to_keep]
        
        ## remove vast-tools' suffix
        psi.columns = [c.replace('_1','') for c in psi.columns]
        
        ## split by event type
        event_types = ["EX","ALTA","ALTD","INT"]
        psis = {e: psi.loc[psi.index.str.contains(e)] for e in event_types}
        
        # TPM
        print("Processing TPM matrix...")
        ## remove vast-tools' suffix
        genexpr.columns = [c.replace('_1','') for c in genexpr.columns]
        
        ## log-transform
        genexpr = np.log2(genexpr + 1)
        
        # subset
        ## find common samples
        common_samples = set(metadata["sampleID"]).intersection(
            psis["EX"].columns
        ).intersection(
            genexpr.columns
        )
        psis = {e: psis[e][common_samples].copy() for e in event_types}
        genexpr = genexpr[common_samples].copy()
        metadata = metadata.loc[metadata["sampleID"].isin(common_samples)]
        
        # save
        print("Saving...")
        ## metadata
        metadata.to_csv(output.metadata, **SAVE_PARAMS)

        ## PSIs
        psis["EX"].reset_index().to_csv(output.psi_EX, **SAVE_PARAMS)
        psis["ALTD"].reset_index().to_csv(output.psi_ALTD, **SAVE_PARAMS)
        psis["ALTA"].reset_index().to_csv(output.psi_ALTA, **SAVE_PARAMS)
        psis["INT"].reset_index().to_csv(output.psi_INT, **SAVE_PARAMS)
        
        ## TPMs
        genexpr.reset_index().drop(columns='NAME').to_csv(output.genexpr, **SAVE_PARAMS)
        
        print("Done!")
        
        
rule delta_psi_ena_splicing_factors:
    input:
        metadata = os.path.join(PREP_DIR,'metadata','ENASFS.tsv.gz'),
        psi = os.path.join(PREP_DIR,'event_psi','ENASFS-{event_type}.tsv.gz')
    output:
        delta_psi = os.path.join(PREP_DIR,'pert_transcriptomes','ENASFS','delta_psi-{event_type}.tsv.gz')
    run:
        import pandas as pd
        
        # load
        metadata = pd.read_table(input.metadata)
        psi = pd.read_table(input.psi, index_col=0)
        
        # delta PSI as the difference between conditions and the mean of the conditions
        delta_psi = {}
        for sample_oi in metadata["sampleID"]:
            # get the controls of the sample
            ctls = metadata.loc[metadata["sampleID"]==sample_oi, "control_samples"].values[0]
            
            # controls will be np.nan
            if isinstance(ctls,str):
                ctls = ctls.split("||")
                psi_ctls = psi[ctls].mean(axis=1)
                
                # compute delta PSI
                dpsi = psi[sample_oi] - psi_ctls
                
                delta_psi[sample_oi] = dpsi
                
                del dpsi, psi_ctls, ctls
                
        
        delta_psi = pd.DataFrame(delta_psi)
        
        # save
        delta_psi.reset_index().to_csv(output.delta_psi, **SAVE_PARAMS)
        
        print("Done!")

        
rule prepare_ground_truth_pert_dpsi_ena_sfs:
    input:
        metadata = os.path.join(PREP_DIR,'metadata','ENASFS.tsv.gz'),
        dpsi = os.path.join(PREP_DIR,'pert_transcriptomes','ENASFS','delta_psi-{event_type}.tsv.gz')
    output:
        dpsi = os.path.join(PREP_DIR,'ground_truth_pert','ENASFS','delta_psi-{event_type}.tsv.gz')
    run:
        import pandas as pd
        
        metadata = pd.read_table(input.metadata)
        dpsi = pd.read_table(input.dpsi, index_col=0)
        
        # drop control samples
        metadata = metadata.loc[~metadata["PERT_ENSEMBL"].isnull()].copy()
        metadata["PERT_ID"] = metadata[
            ["study_accession","cell_line_name","PERT_ENSEMBL"]
        ].apply(lambda row: '___'.join(row.values.astype(str)), axis=1)
        
        dpsis = []
        for pert_id in metadata["PERT_ID"].unique():
            samples_oi = metadata.loc[metadata["PERT_ID"]==pert_id, "sampleID"]

            dpsi_avg = dpsi[samples_oi].mean(axis=1)
            dpsi_avg.name = pert_id
            dpsis.append(dpsi_avg)

        dpsis = pd.concat(dpsis, axis=1)

        dpsis.reset_index().to_csv(output.dpsi, **SAVE_PARAMS)
        
        print("Done!")
        
        
rule preprocess_CardosoMoreira2020:
    input:
        metadata = os.path.join(SUPPORT_DIR,"ENA_filereport-PRJEB26969-CardosoMoreira2020.tsv"),
        psi = os.path.join(RAW_DIR,"articles","CardosoMoreira2020",'vast_out','PSI-minN_1-minSD_0-noVLOW-min_ALT_use25-Tidy.tab.gz'),
        genexpr = os.path.join(RAW_DIR,"articles","CardosoMoreira2020",'vast_out','TPM-hg38-313.tab.gz')
    output:
        metadata = os.path.join(PREP_DIR,"metadata","CardosoMoreira2020.tsv.gz"),
        psi_EX = os.path.join(PREP_DIR,'event_psi','CardosoMoreira2020-EX.tsv.gz'),
        psi_ALTA = os.path.join(PREP_DIR,'event_psi','CardosoMoreira2020-ALTA.tsv.gz'),
        psi_ALTD = os.path.join(PREP_DIR,'event_psi','CardosoMoreira2020-ALTD.tsv.gz'),
        psi_INT = os.path.join(PREP_DIR,'event_psi','CardosoMoreira2020-INT.tsv.gz'),
        genexpr = os.path.join(PREP_DIR,'genexpr_tpm','CardosoMoreira2020.tsv.gz')      
    run:
        import gc
        import pandas as pd
        import numpy as np
        
        # load
        print("Loading data...")
        metadata = pd.read_table(input.metadata)
        psi = pd.read_table(input.psi, index_col=0)
        genexpr = pd.read_table(input.genexpr, index_col=[0,1])
        
        gc.collect()
        
        # metadata
        metadata["sampleID"] = metadata["run_accession"]
        
        # PSI
        print("Processing PSI matrix...")
        ## drop empty rows
        is_na = psi.isnull()
        non_missing = is_na.shape[1] - is_na.sum(1)
        to_keep = non_missing >= 1
        psi = psi.loc[to_keep]
        
        ## remove vast-tools' suffix
        psi.columns = [c.replace('_1','') for c in psi.columns]
        
        ## split by event type
        event_types = ["EX","ALTA","ALTD","INT"]
        psis = {e: psi.loc[psi.index.str.contains(e)] for e in event_types}
        
        # TPM
        print("Processing TPM matrix...")
        ## remove vast-tools' suffix
        genexpr.columns = [c.replace('_1','') for c in genexpr.columns]
        
        ## log-transform
        genexpr = np.log2(genexpr + 1)
        
        # subset
        ## find common samples
        common_samples = set(metadata["run_accession"]).intersection(
            psis["EX"].columns
        ).intersection(
            genexpr.columns
        )
        psis = {e: psis[e][common_samples].copy() for e in event_types}
        genexpr = genexpr[common_samples].copy()
        metadata = metadata.loc[metadata["run_accession"].isin(common_samples)]
        
        # save
        print("Saving...")
        ## metadata
        metadata.to_csv(output.metadata, **SAVE_PARAMS)

        ## PSIs
        psis["EX"].reset_index().to_csv(output.psi_EX, **SAVE_PARAMS)
        psis["ALTD"].reset_index().to_csv(output.psi_ALTD, **SAVE_PARAMS)
        psis["ALTA"].reset_index().to_csv(output.psi_ALTA, **SAVE_PARAMS)
        psis["INT"].reset_index().to_csv(output.psi_INT, **SAVE_PARAMS)
        
        ## TPMs
        genexpr.reset_index().drop(columns='NAME').to_csv(output.genexpr, **SAVE_PARAMS)
        
        print("Done!")
        
        
# rule discretize_matrix_gaussian:
#     input:
#         matrix = os.path.join(PREP_DIR,"{data_type}","{dataset}-EX.tsv.gz")
#     output:
#         matrix = os.path.join(PREP_DIR,"{data_type}_discretized_gaussian","{dataset}-EX.tsv.gz")
#     run:
#         import pandas as pd
#         import numpy as np
#         from sklearn.mixture import GaussianMixture
        
#         # load
#         X = pd.read_table(input.matrix, index_col=0)
        
#         # discretize
#         def discretize(x):
#             try:
#                 # fit gaussian mixture
#                 gmm = GaussianMixture(n_components=2)
#                 gmm.fit(x.values.reshape(-1, 1))
#                 probs = gmm.predict_proba(x.values.reshape(-1, 1))
#             except:
#                 probs = np.zeros((len(x),2))
            
#             # split into groups
#             groupA = probs[:,0] > probs[:,1]
#             groupB = probs[:,0] <= probs[:,1]
            
#             # determine which group is high (1) or low (0)
#             discretized = x.copy()
#             discretized.values[:] = 0
#             if x[groupA].median() > x[groupB].median():
#                 discretized.values[groupA] = 1
#             elif x[groupA].median() < x[groupB].median():
#                 discretized.values[groupB] = 1
            
#             # if they are not different we keep all zeros
            
#             return discretized
            
#         result = X.apply(discretize, axis=1)
        
#         # save
#         result.to_csv(output.matrix, **SAVE_PARAMS)
        
#         print("Done!")
        
        
rule discretize_matrix_qep_splicing:        
    input:
        matrix = os.path.join(PREP_DIR,"event_psi_imputed","{dataset}-EX.tsv.gz")
    output:
        matrix = os.path.join(PREP_DIR,"event_psi_imputed_discretized_qep","{dataset}-EX.tsv.gz")
    shell:
        """
        Rscript scripts/discretize_matrix_qep.R \
                    --matrix_file={input.matrix} \
                    --output_file={output.matrix}
        """
        
        
rule discretize_matrix_qep_genexpr:        
    input:
        matrix = os.path.join(PREP_DIR,"genexpr_tpm","{dataset}.tsv.gz")
    output:
        matrix = os.path.join(PREP_DIR,"genexpr_tpm_discretized_qep","{dataset}.tsv.gz")
    shell:
        """
        Rscript scripts/discretize_matrix_qep.R \
                    --matrix_file={input.matrix} \
                    --output_file={output.matrix}
        """

        
rule figures_eda:
    input:
        splicing_factors = os.path.join(SUPPORT_DIR,"splicing_factors","splicing_factors.tsv"),
        metadata_encore_kd = os.path.join(PREP_DIR,"metadata","ENCOREKD.tsv.gz"),
        metadata_encore_ko = os.path.join(PREP_DIR,"metadata","ENCOREKO.tsv.gz"),
        kd_screen = os.path.join(SUPPORT_DIR,"kd_screen-symbol.txt"),
        ena_sfs = os.path.join(SUPPORT_DIR,"ENA_filereport-selected_sf_experiments_handcurated.tsv")
    output:
        directory(os.path.join(RESULTS_DIR,'figures','eda'))
    shell:
        """
        Rscript scripts/figures_eda.R \
                    --splicing_factors_file={input.splicing_factors} \
                    --metadata_encore_kd_file={input.metadata_encore_kd} \
                    --metadata_encore_ko_file={input.metadata_encore_ko} \
                    --kd_screen_file={input.kd_screen} \
                    --ena_sfs_file={input.ena_sfs} \
                    --figs_dir={output}
        """
        
