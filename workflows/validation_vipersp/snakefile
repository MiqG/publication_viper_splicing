"""
Author: Miquel Anglada Girotto
Contact: miquelangladagirotto [at] gmail [dot] com
"""

import os

# variables
ROOT = os.path.dirname(os.path.dirname(os.getcwd()))
RAW_DIR = os.path.join(ROOT,"data","raw")
PREP_DIR = os.path.join(ROOT,"data","prep")
SUPPORT_DIR = os.path.join(ROOT,"support")
RESULTS_DIR = os.path.join(ROOT,"results","validation_vipersp")

METHODS_INFER = ["correlation_pearson","correlation_spearman"]
CELL_LINES = ["K562","HepG2"]

THRESH_DELTA_PSI = 10
THRESH_FDR = 0.05

CANCER_TYPES = [
    #"BLCA",
    #"BRCA",
    #"COAD",
    #"HNSC",
    #"KICH",
    #"KIRC",
    #"KIRP",
    "LIHC",
    #"LUAD",
    #"LUSC",
    #"PRAD",
    #"THCA",
    #"UCEC"
]

##### RULES #####
rule all:
    input:
        # make SF networks for cancer cell lines
        expand(os.path.join(RESULTS_DIR,'files','ground_truth_regulon','ENCORE','{cell_line}.tsv.gz'), cell_line=CELL_LINES),
        expand(os.path.join(RESULTS_DIR,'files','diff_genexpr_regulon','TCGA','{cancer_type}','regulons.tsv.gz'), cancer_type=CANCER_TYPES),
        expand(os.path.join(RESULTS_DIR,'files','diff_genexpr_regulon','TCGA','{cancer_type}','sample_info.tsv.gz'), cancer_type=CANCER_TYPES),
        
        # run the VIPER algorithm with the ENCORE delta PSIs and ground truth SF networks
        expand(os.path.join(RESULTS_DIR,'files','validations','ENCORE','{cell_line}-regulon_{cancer_type}.tsv.gz'), cell_line=CELL_LINES, cancer_type=CANCER_TYPES),
        
        # make figures
        
        
rule make_ground_truth_sf_regulons:
    input:
        ground_truth_kd_dpsi = os.path.join(PREP_DIR,'ground_truth_kd','ENCORE',"{cell_line}",'delta_psi-EX.tsv.gz')
    output:
        ground_truth_sf_regulons = os.path.join(RESULTS_DIR,'files','ground_truth_regulon','ENCORE','{cell_line}.tsv.gz')
    params:
        thresh_delta_psi = THRESH_DELTA_PSI
    run:
        import pandas as pd
        import numpy as np
        
        # load
        print('Loading...')
        ground_truth_kd_dpsi = pd.read_table(input.ground_truth_kd_dpsi)
        thresh_delta_psi = params.thresh_delta_psi
        
        # make regulon
        print('Preparing regulons...')
        edges = ground_truth_kd_dpsi.melt(id_vars=['EVENT'], var_name='ENSEMBL', value_name='delta_psi')
        ## likelihood: delta PSI between 0 and 1
        edges['likelihood'] = np.abs(edges['delta_psi']) / 100
        ## tfmode: sign of delta PSI, either -1 or 1
        edges['tfmode'] = np.sign(edges['delta_psi'])
        ## add splicing_factor and target columns
        edges['splicing_factor'] = edges['ENSEMBL']
        edges['target'] = edges['EVENT']
        ## filter out irrelevant splicing changes
        edges = edges.loc[np.abs(edges['delta_psi']) > thresh_delta_psi].copy()
        
        # save
        print('Saving...')
        edges.to_csv(output.ground_truth_sf_regulons, sep='\t', compression='gzip', index=None)
        
        print('Done!')
        
        
rule make_sf_regulons_tcga:
    input:
        genexpr = "/home/miquel/projects/publication_spotter/data/prep/genexpr_tpm/{cancer_type}.tsv.gz",
        psi = "/home/miquel/projects/publication_spotter/data/prep/event_psi/{cancer_type}-EX.tsv.gz",
        metadata = "/home/miquel/projects/publication_spotter/data/prep/metadata/{cancer_type}.tsv.gz",
        splicing_factors = os.path.join(SUPPORT_DIR,"GOBP_RNA_SPLICING-ensembl.txt")
    output:
        sf_regulons = os.path.join(RESULTS_DIR,'files','diff_genexpr_regulon','TCGA','{cancer_type}','regulons.tsv.gz'),
        sample_info = os.path.join(RESULTS_DIR,'files','diff_genexpr_regulon','TCGA','{cancer_type}','sample_info.tsv.gz')
    params:
        n_extreme = 50,
        thresh_delta_psi = THRESH_DELTA_PSI,
        thresh_fdr = THRESH_FDR,
        n_jobs = 20
    threads: 20
    run:
        import pandas as pd
        import numpy as np
        from scipy import stats
        from statsmodels.stats import multitest
        from joblib import Parallel, delayed
        from tqdm import tqdm

        # load
        print('Loading...')
        genexpr = pd.read_table(input.genexpr, index_col=0)
        psi = pd.read_table(input.psi, index_col=0)
        metadata = pd.read_table(input.metadata)
        splicing_factors = list(pd.read_table(input.splicing_factors, header=None)[0])
        n_extreme = params.n_extreme
        thresh_delta_psi = params.thresh_delta_psi
        thresh_fdr = params.thresh_fdr
        n_jobs = threads
        
        # prep
        ## only primary tumors
        samples_oi = metadata.loc[metadata["sample_type"] == "Primary Tumor","sampleID"]
        genexpr = genexpr.loc[:,genexpr.columns.isin(samples_oi)].copy()
        
        # make regulon
        print('Preparing regulons...')
        ## label samples with extreme gene expression
        genexpr = genexpr.loc[genexpr.index.isin(splicing_factors)].melt(ignore_index=False).reset_index()
        genexpr = genexpr.rename(columns={'ID':'splicing_factor', 'variable':'sampleID', 'value':'tpm'})
        genexpr['log_tpm'] = np.log2(genexpr['tpm'] + 1)
        genexpr = genexpr.dropna().sort_values(['splicing_factor','log_tpm'])
        
        def classify_samples(df, n_extreme):
            df = df.sort_values('log_tpm')
            high_samples = df.tail(n_extreme)['sampleID']
            low_samples = df.head(n_extreme)['sampleID']
            df['sf_expr'] = 'medium'
            df.loc[df['sampleID'].isin(high_samples), 'sf_expr'] = 'high'
            df.loc[df['sampleID'].isin(low_samples), 'sf_expr'] = 'low'
            df['log_fc_tpm'] = np.median(df.loc[df['sampleID'].isin(high_samples), 'log_tpm']) - np.median(df.loc[df['sampleID'].isin(low_samples), 'log_tpm'])
            
            return df
        genexpr = pd.concat([classify_samples(df, n_extreme) for sf, df in genexpr.groupby('splicing_factor')])
        genexpr = genexpr.loc[genexpr['sf_expr'].isin(['high','low'])].copy()
        
        # filter PSI
        def filter_psi(psi, sample_info):
            high_samples = list(sample_info.loc[sample_info['sf_expr']=='high', 'sampleID'])
            low_samples = list(sample_info.loc[sample_info['sf_expr']=='low', 'sampleID'])
            samples_oi = high_samples+low_samples
            
            # drop empty rows
            X = psi[samples_oi].copy()
            is_na = X.isnull()
            non_missing = is_na.shape[1] - is_na.sum(1)
            to_keep = non_missing >= 1
            X = X.loc[to_keep].copy()
            
            # drop rows without at least N observations per group
            is_na = X.isnull()
            n_obs_high = len(high_samples) - is_na[high_samples].sum(axis=1)
            n_obs_low = len(low_samples) - is_na[low_samples].sum(axis=1)
            to_keep = (n_obs_high>=20) & (n_obs_low>=20)
            X = X.loc[to_keep].copy()
            
            # drop rows that with constant PSI
            to_keep = X.std(axis=1)>0
            X = X.loc[to_keep].copy()
            
            return X
            
        # differential splicing analysis between high vs low expression of each SF
        def test(a, b):
            a = a[np.isfinite(a)]
            b = b[np.isfinite(b)]
            
            try: 
                statistic, pvalue = stats.mannwhitneyu(a, b)
                result = pd.Series({
                    'median_a': np.median(a),
                    'median_b': np.median(b),
                    'median_diff': np.median(a) - np.median(b),
                    'statistic': statistic,
                    'pvalue': pvalue,
                    'n_samples_a': len(a),
                    'n_samples_b': len(b)
                })
            except:
                result = pd.Series({
                    'median_a': np.nan,
                    'median_b': np.nan,
                    'median_diff': np.nan,
                    'statistic': np.nan,
                    'pvalue': np.nan,
                    'n_samples_a': np.nan,
                    'n_samples_b': np.nan
                })
            return result
            
        def dsa(psi, sample_info, thresh_delta_psi, sf):
            # get samples
            high_samples = list(sample_info.loc[sample_info['sf_expr']=='high', 'sampleID'])
            low_samples = list(sample_info.loc[sample_info['sf_expr']=='low', 'sampleID'])
            
            # filter uninformative exons
            psi_filtered = filter_psi(psi, sample_info)
            
            # test
            result = psi_filtered.apply(
                lambda x: test(a=x[high_samples], b=x[low_samples]), axis=1
            ).reset_index()
            result['padj'] = np.nan
            _, fdr, _, _ = multitest.multipletests(
                result.loc[np.isfinite(result['pvalue']),'pvalue'], method='fdr_bh'
            )
            result.loc[np.isfinite(result['pvalue']),'padj'] = fdr
            
            # filter out irrelevant splicing changes
            #result = result.loc[np.abs(result['median_diff']) > thresh_delta_psi].copy()
            
            # add SF
            result["splicing_factor"] = sf
            
            return result
        
        result = Parallel(n_jobs=n_jobs)(
            delayed(dsa)(
                psi, sample_info, thresh_delta_psi, sf
            )
            for sf, sample_info in tqdm(genexpr.groupby('splicing_factor'))
        )
        result = pd.concat(result)
        
        # prepare regulons
        edges = result
        ## likelihood: delta PSI between 0 and 1
        edges['likelihood'] = np.abs(edges['median_diff']) / 100
        ## tfmode: sign of delta PSI, either -1 or 1
        edges['tfmode'] = np.sign(edges['median_diff'])
        ## add splicing_factor columns
        edges['target'] = edges['EVENT']
        ## filter out irrelevant splicing changes
        edges = edges.loc[edges['padj'] < thresh_fdr].copy()
        
        # save
        print('Saving...')
        edges.to_csv(output.sf_regulons, sep='\t', compression='gzip', index=None)
        genexpr.to_csv(output.sample_info, sep='\t', compression='gzip', index=None)
        
        print('Done!')
        
        
rule run_viper_on_encore:
    input:
        delta_psi = os.path.join(PREP_DIR,'ground_truth_kd','ENCORE',"{cell_line}",'delta_psi-EX.tsv.gz'),
        regulons = os.path.join(RESULTS_DIR,'files','diff_genexpr_regulon','TCGA','{cancer_type}','regulons.tsv.gz')
    output:
        os.path.join(RESULTS_DIR,'files','validations','ENCORE','{cell_line}-regulon_{cancer_type}.tsv.gz')
    shell:
        """
        Rscript scripts/run_viper.R \
                    --delta_psi_file={input.delta_psi} \
                    --regulons_file={input.regulons} \
                    --output_file={output}
        """